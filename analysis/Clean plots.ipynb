{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63badda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "dataset_dir = \"../data_prep/final_dataset/\"\n",
    "\n",
    "SUBSETS = \"train dev test\".split()\n",
    "\n",
    "datasets = collections.defaultdict(list)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    for filename in glob.glob(dataset_dir + subset + \"/*\"):\n",
    "        with open(filename, 'r') as f:\n",
    "            datasets[subset].append(json.load(f))\n",
    "            \n",
    "all_pairs = sum(datasets.values(), [])\n",
    "\n",
    "DPI = 150\n",
    "\n",
    "\n",
    "FigText = collections.namedtuple(\"c\", \"x y text ha va rotation\".split())\n",
    "plt.rcParams.update({'font.size':'12',\n",
    "                     'hatch.color': 'w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c80b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"Dark2\")\n",
    "OVERALL_COLOR, REQUEST_COLOR, EVAL_COLOR, FACT_COLOR, STRUCT_COLOR = palette[:5]\n",
    "AUX_COLOR = palette[-2]\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmen = []\n",
    "for pair in all_pairs:\n",
    "    alignment_list = []\n",
    "    for sentence in pair[\"rebuttal_sentences\"]:\n",
    "        align_type, align_indices = sentence[\"alignment\"]\n",
    "        if align_type == \"context_sentences\":\n",
    "            for review_index in align_indices:\n",
    "                alignment_list.append([sentence[\"sentence_index\"], review_index])\n",
    "    if not alignment_list:\n",
    "        continue\n",
    "    a, b = zip(*alignment_list)\n",
    "    if len(set(a)) == 1 or len(set(b)) == 1:\n",
    "        continue\n",
    "    spearmen.append(stats.spearmanr(*zip(*alignment_list)).correlation)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "fig = sns.histplot(spearmen, bins=100, color=OVERALL_COLOR)\n",
    "plt.ylabel(\"Number of review-rebuttal pairs\")\n",
    "plt.xlabel(\"Spearman's rho (rebuttal sent. idxs v/s aligned review sent. idxs)\")\n",
    "\n",
    "plt.savefig(\"figs/spearmen.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e378a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sentence_counter = {}\n",
    "\n",
    "for pair in all_pairs:\n",
    "    review_id = pair[\"metadata\"][\"review_id\"]\n",
    "    review_sentence_counter[review_id] = {\n",
    "        \"mapped\": [False]* len(pair[\"review_sentences\"]),\n",
    "        \"arg_type\": [sentence[\"coarse\"] for sentence in pair[\"review_sentences\"]]}\n",
    "    for rebuttal_sentence in pair[\"rebuttal_sentences\"]:\n",
    "        align_type, aligned = rebuttal_sentence[\"alignment\"]\n",
    "        if align_type == \"context_sentences\":\n",
    "            for index in aligned:\n",
    "                try:\n",
    "                    review_sentence_counter[review_id][\"mapped\"][index] = True\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                \n",
    "color_list = [OVERALL_COLOR, REQUEST_COLOR, EVAL_COLOR, FACT_COLOR]\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12,5), sharex=True, dpi=DPI)\n",
    "\n",
    "coverages = []\n",
    "for review_id, mappyloo in review_sentence_counter.items():\n",
    "    coverages.append(sum(mappyloo[\"mapped\"])/len(mappyloo[\"mapped\"]))\n",
    "sns.histplot(coverages, ax=axs[0], bins=20, color=color_list[0])\n",
    "\n",
    "axs[0].yaxis.label.set_visible(False)\n",
    "\n",
    "for i, arg_type in enumerate(\"overall request evaluative fact\".split()):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    actual_arg_type = \"arg_\" + arg_type\n",
    "\n",
    "    coverages = []\n",
    "    for review_id, mappyloo in review_sentence_counter.items():\n",
    "        filtered = [mappyloo[\"mapped\"][j] for j, t in enumerate(mappyloo[\"arg_type\"]) if t == actual_arg_type]\n",
    "        if not filtered:\n",
    "            continue\n",
    "        coverages.append(sum(filtered)/len(filtered))\n",
    "\n",
    "\n",
    "    sns.histplot(coverages, ax=axs[i], bins=20, color=color_list[i])\n",
    "\n",
    "    \n",
    "y_axis_label = FigText(0.07, 0.5, \"Number of reviews\", \"left\", \"center\", \"vertical\")\n",
    "x_axis_label = FigText(0.5, 0.01,\n",
    "                       'Proportion of review sentences with direct responses, by action type',\n",
    "                       \"center\", \"bottom\", \"horizontal\")\n",
    "plot_labels = [\n",
    "    x_axis_label, y_axis_label,\n",
    "    FigText(0.75, 0.62, 'Request', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.75, 0.43, 'Evaluative', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.75, 0.22, 'Fact', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.75, 0.82, 'All actions', \"left\", \"center\", \"horizontal\"),\n",
    "]\n",
    "\n",
    "\n",
    "for ft in plot_labels:\n",
    "    fig.text(ft.x, ft.y, ft.text, ha=ft.ha, va=ft.va, rotation=ft.rotation)\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].spines['right'].set_visible(False)\n",
    "    axs[i].yaxis.label.set_visible(False)\n",
    "\n",
    "\n",
    "plt.savefig(\"figs/coverage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreeability v/s variance\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_agreeability(pair_obj):\n",
    "    coarse_counter = collections.Counter()\n",
    "    for sentence in pair_obj[\"rebuttal_sentences\"]:\n",
    "        coarse_counter[sentence['coarse']] += 1\n",
    "    if 'concur' not in coarse_counter and 'dispute' not in coarse_counter:\n",
    "        return {'agreeability': None}\n",
    "    return {\n",
    "      \"agreeability\":\n",
    "        coarse_counter['concur'] / (coarse_counter['concur'] + coarse_counter['dispute'])\n",
    "    }\n",
    "\n",
    "def draw_constant_line(value, other_axis_values, is_horizontal):\n",
    "    pass\n",
    "\n",
    "forum_agreeability_map = collections.defaultdict(list)\n",
    "\n",
    "for pair in all_pairs:\n",
    "    forum_agreeability_map[pair[\"metadata\"][\"forum_id\"]].append((get_agreeability(pair)[\"agreeability\"],pair[\"metadata\"][\"rating\"] ))\n",
    "\n",
    "agreeability_df_dicts = []\n",
    "\n",
    "\n",
    "# Column names\n",
    "agree_mean, rating_var, avg_rating = [\"Mean agreeability score\", \"Variance in rating across reviewers\", \"Average rating\"]\n",
    "    \n",
    "for forum, info in forum_agreeability_map.items():\n",
    "    if len(info) == 1:\n",
    "        continue\n",
    "    agreeabilities, ratings = list(zip(*info))\n",
    "    if None in agreeabilities:\n",
    "        continue\n",
    "    agreeability_df_dicts.append({agree_mean: np.mean(agreeabilities),\n",
    "                                 rating_var: np.var(ratings),\n",
    "                                 avg_rating: np.mean(ratings)})\n",
    "    \n",
    "agreeability_df = pd.DataFrame.from_dict(agreeability_df_dicts)\n",
    "\n",
    "agreeability_first_quartile = agreeability_df.quantile(0.25)[agree_mean]\n",
    "variance_third_quartile = agreeability_df.quantile(0.75)[rating_var]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=DPI)\n",
    "ax = sns.scatterplot(\n",
    "    data=agreeability_df,\n",
    "    x=agree_mean,\n",
    "    y=rating_var,\n",
    "    hue=avg_rating, s=100,palette=sns.light_palette(OVERALL_COLOR, as_cmap=True))\n",
    "plt.plot([agreeability_first_quartile,agreeability_first_quartile], [0,8.5], linestyle=\"dashed\", color=AUX_COLOR)\n",
    "plt.plot([0,1], [variance_third_quartile,variance_third_quartile], linestyle=\"dotted\", color=AUX_COLOR)\n",
    "\n",
    "\n",
    "plot_labels = [\n",
    "    FigText(0.5, 9.4, 'Authors agree with reviewers more', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(1.06, 5, \"Reviewers agree with each other more\", \"right\", \"center\", 270)\n",
    "]\n",
    "\n",
    "\n",
    "ax.arrow(0.3, 9.1, 0.65,0, head_width=0.25, head_length=0.03, fc='k', ec='k')\n",
    "\n",
    "ax.arrow(1.03, 9, 0, -8, head_width=0.018, head_length=0.4, fc='k', ec='k')\n",
    "\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "for ft in plot_labels:\n",
    "    plt.text(ft.x, ft.y, ft.text, ha=ft.ha, va=ft.va, rotation=ft.rotation)\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/agreeability.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "j = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "for example in all_pairs:\n",
    "    review_coarse_labels = [sentence[\"coarse\"] for sentence in example[\"review_sentences\"]]\n",
    "    for rebuttal_sentence in example[\"rebuttal_sentences\"]:\n",
    "        fine = rebuttal_sentence[\"fine\"]\n",
    "        align_type, aligned_idxs = rebuttal_sentence[\"alignment\"]\n",
    "        if align_type == \"context_sentences\":\n",
    "            for aligned_idx in rebuttal_sentence[\"alignment\"][1]:\n",
    "                try:\n",
    "                    j[fine][review_coarse_labels[aligned_idx]] += 1\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "review_types = \"arg_request arg_evaluative arg_fact arg_structuring arg_social arg_other\".split()\n",
    "\n",
    "type_name_map = {\n",
    "    \"arg_request\": \"Request\",\n",
    "    \"arg_evaluative\": \"Evaluative\",\n",
    "    \"arg_fact\": \"Fact\",\n",
    "    \"arg_social\": \"Social\",\n",
    "    \"arg_structuring\": \"Structuring\",\n",
    "    \"arg_other\": \"Other\",\n",
    "}\n",
    "\n",
    "full_eval_responses = [\n",
    "    \"rebuttal_accept-praise\",\n",
    "\"rebuttal_concede-criticism\",\n",
    "\"rebuttal_mitigate-criticism\",\n",
    "\"rebuttal_reject-criticism\",\n",
    "]\n",
    "\n",
    "full_request_responses = [\n",
    "    \"rebuttal_answer\",\n",
    "\"rebuttal_by-cr\",\n",
    "\"rebuttal_done\",\n",
    "\"rebuttal_future\",\n",
    "\"rebuttal_refute-question\",\n",
    "\"rebuttal_reject-request\",\n",
    "]\n",
    "\n",
    "eval_responses = [\n",
    "\"rebuttal_concede-criticism\",\n",
    "]\n",
    "\n",
    "request_responses = [\n",
    "    \"rebuttal_answer\",\n",
    "\"rebuttal_done\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(eval_responses + request_responses), ncols=1, figsize=(12,6), dpi=DPI)\n",
    "\n",
    "k=sns.color_palette(\"crest\", 2)\n",
    "\n",
    "\n",
    "ax_count = 0\n",
    "for key in sorted(eval_responses) + sorted(request_responses):\n",
    "    vals = j[key]\n",
    "    bar = sns.barplot(x=[type_name_map[i] for i in review_types], y=[vals[i] for i in review_types],ax=axes[ax_count], palette=[REQUEST_COLOR, EVAL_COLOR, FACT_COLOR, STRUCT_COLOR, OVERALL_COLOR, OVERALL_COLOR])\n",
    "    \n",
    "    if key in eval_responses:\n",
    "        bar.patches[1].set_hatch(\"/\")\n",
    "    elif key in request_responses:\n",
    "        bar.patches[0].set_hatch(\"/\")\n",
    "    else:\n",
    "        assert False\n",
    "    #bar.set_edgecolor([0.5,0.5,0.5])\n",
    "    axes[ax_count].set_ylabel(key[9:])\n",
    "    ax_count += 1\n",
    "    \n",
    "\n",
    "for i in range(3):\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].yaxis.label.set_visible(False)\n",
    "\n",
    "plot_labels = [\n",
    "    FigText(0.5, 0.8, 'Contexts of \"Concede criticism\" sentences', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.5, 0.55, 'Contexts of \"Answer\" sentences', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.5, 0.28, 'Contexts of \"Task has been done\" sentences', \"left\", \"center\", \"horizontal\"),\n",
    "    FigText(0.06, 0.5, \"Number of rebuttal sentences\", \"left\", \"center\", \"vertical\")\n",
    "]\n",
    "\n",
    "\n",
    "for ft in plot_labels:\n",
    "    fig.text(ft.x, ft.y, ft.text, ha=ft.ha, va=ft.va, rotation=ft.rotation)\n",
    "    \n",
    "    \n",
    "plt.savefig(\"figs/noncanonical.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093f458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
