{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import openreview\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "dataset_dir = \"data_prep/final_dataset/\"\n",
    "\n",
    "SUBSETS = \"train dev test\".split()\n",
    "\n",
    "datasets = collections.defaultdict(list)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    for filename in glob.glob(dataset_dir + subset + \"/*\"):\n",
    "        with open(filename, 'r') as f:\n",
    "            datasets[subset].append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdcf67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def total_and_average_len(list_of_lists):\n",
    "    #print(list_of_lists)\n",
    "    big_list = sum(list_of_lists, [])\n",
    "    return len(big_list), len(big_list)/len(list_of_lists)\n",
    "\n",
    "def count_dataset(pairs, subset):\n",
    "    # TODO: Add double-annotated and adjudicated\n",
    "    review_total, review_average = total_and_average_len([pair[\"review_sentences\"] for pair in pairs])\n",
    "    rebuttal_total, rebuttal_average = total_and_average_len([pair[\"rebuttal_sentences\"] for pair in pairs])\n",
    "    return {\n",
    "        \"subset\":subset,\n",
    "        \"pairs\": len(pairs),\n",
    "        \"forums\": len(set(pair[\"metadata\"][\"forum_id\"] for pair in pairs)),\n",
    "        \"adjudicated\": len([pair for pair in pairs if pair[\"metadata\"][\"annotator\"] == \"anno0\"]),\n",
    "        \"review_sentences\": review_total,\n",
    "        \"rebuttal_sentences\": rebuttal_total,\n",
    "        \"review_avg_sentences\": review_average,\n",
    "        \"rebuttal_avg_sentences\": rebuttal_average,\n",
    "        \n",
    "    }\n",
    "# Distribution of examples over sets\n",
    "df_dicts = [count_dataset(pairs, subset) for subset, pairs in datasets.items()]\n",
    "dataframe = pd.DataFrame.from_dict(df_dicts)\n",
    "\n",
    "dataframe.round(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16927657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd5f180",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review and rebuttal length\n",
    "\n",
    "big_list = sum(datasets.values(), [])\n",
    "\n",
    "length_counter = collections.Counter()\n",
    "\n",
    "for example in big_list:\n",
    "    length_counter[(len(example[\"review_sentences\"]), \n",
    "                    len(example[\"rebuttal_sentences\"]))] += 1\n",
    "df = pd.DataFrame.from_dict([\n",
    "    {\n",
    "        \"review_length\": a,\n",
    "        \"rebuttal_length\": b,\n",
    "        \"count\": count\n",
    "    } for (a, b), count in length_counter.items()\n",
    "])\n",
    "sns.jointplot(x=df.review_length, y=df.rebuttal_length, cmap=\"Blues\", kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f872c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "guest_client = openreview.Client(baseurl='https://api.openreview.net')\n",
    "\n",
    "def get_num_reviews(guest_client, forum_id):\n",
    "    forum_notes = guest_client.get_notes(forum=forum_id)\n",
    "    review_count = 0\n",
    "    for note in forum_notes:\n",
    "        if note.replyto == forum_id and 'Reviewer' in note.signatures[0]:\n",
    "            review_count += 1\n",
    "    return review_count\n",
    "\n",
    "# for subset, examples in datasets.items():\n",
    "#     forum_counter = collections.defaultdict(list)\n",
    "#     for example in tqdm.tqdm(examples[:100]):\n",
    "#         forum_counter[example[\"metadata\"][\"forum_id\"]].append(example[\"metadata\"][\"review_id\"])\n",
    "    \n",
    "    \n",
    "#     percentage_annotated_list = []\n",
    "\n",
    "#     for forum, annotated_reviews in tqdm.tqdm(forum_counter.items()):\n",
    "#         percentage_annotated_list.append(len(annotated_reviews)/get_num_reviews(guest_client, forum))\n",
    "        \n",
    "#     sns.histplot(data=percentage_annotated_list)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotator confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49219b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4ad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
