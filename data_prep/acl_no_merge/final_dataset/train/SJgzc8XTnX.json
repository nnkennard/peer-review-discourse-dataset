{
  "metadata": {
    "forum_id": "HJeu43ActQ",
    "review_id": "SJgzc8XTnX",
    "rebuttal_id": "SJxXh0Q1A7",
    "title": "NOODL: Provable Online Dictionary Learning and Sparse Coding",
    "reviewer": "AnonReviewer2",
    "rating": 7,
    "conference": "ICLR2019",
    "permalink": "https://openreview.net/forum?id=HJeu43ActQ&noteId=SJxXh0Q1A7",
    "annotator": "anno2"
  },
  "review_sentences": [
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 0,
      "text": "The paper considers the problem of dictionary learning.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 1,
      "text": "Here the model that we are given samples y, where we know that y = Ax where A is a dictionary matrix, and x is a random sparse vector.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 2,
      "text": "The goal is typically to recover the dictionary A, from which one can also recover the x under suitable conditions on A. The paper shows that there is an alternating optimization-based algorithm for this problem that under standard assumptions provably converges exactly to the true dictionary and the true coefficients x (up to some negligible bias).",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 3,
      "text": "The main comparison with prior work",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 4,
      "text": "is with [1].",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 5,
      "text": "Both give algorithms of this type for the same problem, with similar assumptions (although there is some difference; see below).",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 6,
      "text": "In [1], the authors give two algorithms: one with a better sample complexity than the algorithm presented here, but which has some systematic, somewhat large, error floor which it cannot exceed, and another which can obtain similar rates of convergence to the exact solution, but which requires polynomial sample complexity (the explicit bound is not stated in the paper).",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 7,
      "text": "The algorithm here seems to build off of the former algorithm; essentially replacing a single hard thresholding step with an IHT-like step.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 8,
      "text": "This update rule is able to remove the error floor and achieve exact recovery.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 9,
      "text": "However, this makes the analysis substantially more difficult.",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 10,
      "text": "I am not an expert in this area, but this seems like a nice and non-trivial result.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 11,
      "text": "The proofs are quite dense and I was unable to verify them carefully.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_replicability",
      "pol": "pol_negative"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 12,
      "text": "Comments:",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 13,
      "text": "- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_soundness-correctness",
      "pol": "pol_negative"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 14,
      "text": "The authors claim that some amount of noise can be tolerated, but do not quantify how much.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_soundness-correctness",
      "pol": "pol_negative"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 15,
      "text": "- A.4 makes it sound like eps_t needs to be assumed to be bounded, when all that is required is the bound on eps_0.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_soundness-correctness",
      "pol": "pol_negative"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 16,
      "text": "[1] Arora, S. Ge, R., Ma, T. and Moitra, A. Simple, Efficient, and Neural Algorithms for Sparse Coding.",
      "suffix": "",
      "coarse": "arg_other",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "SJgzc8XTnX",
      "sentence_index": 17,
      "text": "COLT 2015.",
      "suffix": "",
      "coarse": "none",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    }
  ],
  "rebuttal_sentences": [
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 0,
      "text": "We would like to thank the reviewer for the comments and for raising some subtle yet important questions.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 1,
      "text": "We address and clarify specific comments below.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_structuring",
      "alignment": [
        "context_in-rebuttal",
        null
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 2,
      "text": "We have also made corresponding changes in the revised paper, and have added a proof map, in addition to the Table 3, for easier navigation of the results.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_other",
      "alignment": [
        "context_none",
        null
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 3,
      "text": "We have also added comparisons with Mairal `09, and experimental evaluation of computational time.",
      "suffix": "\n\n",
      "coarse": "nonarg",
      "fine": "rebuttal_other",
      "alignment": [
        "context_none",
        null
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 4,
      "text": "1. Noise Tolerance \u2014 NOODL also has similar tolerance to noise as Arora et. al. 2015 and can be used in noisy settings as well.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 5,
      "text": "We focus on the noiseless case here to convey the main idea, since the analysis is already very involved.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 6,
      "text": "Nevertheless, the proposed algorithm can tolerate i.i.d. sub-Gaussian noise, including Gaussian noise and bounded noise, as long as the ``noise\u2019\u2019 is dominated by the ``signal\u2019\u2019.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 7,
      "text": "Under the noisy case, the recovered dictionary and coefficients will converge to a neighborhood of the true factors, where the neighborhood is defined by the properties of the additive noise.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 8,
      "text": "In other words, the noise terms will lead to additional terms which will need to be controlled for the convergence analysis.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 9,
      "text": "Specifically, the noise will add a term to the coefficient update in Lemma 2, and will effect the threshold, tau.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 10,
      "text": "For the dictionary, the noise will result in additional terms in Lemma 9 (which ensures that the updated dictionary maintains the closeness property).",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 11,
      "text": "A precise characterization of the relationship between the level of noise the size of convergence neighborhood requires careful analysis, which we defer to future effort.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_future",
      "alignment": [
        "context_sentences",
        [
          13,
          14
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 12,
      "text": "2. On eps_t and A.4. \u2014  Indeed, we don\u2019t need to assume that eps_t is bounded.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          15
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 13,
      "text": "Specifically, using the result of Lemma 7, we have that eps_0 undergoes a contraction at every step, therefore, eps_t <= eps_0.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          15
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 14,
      "text": "For our analysis we fix eps_t = O^*(1/log(n)), which follows from the assumption on eps_0= O^*(1/log(n)) and Lemma 7.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          15
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 15,
      "text": "On reviewer\u2019s comments, we have updated A.4., and moved the note about eps_t = O^*(1/log(n)) to the Appendix A.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          15
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 16,
      "text": "3. Exact recovery of factors \u2014 Also, we would like to point that NOODL recovers both the dictionary and coefficients exactly at a geometric rate.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          8,
          9
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 17,
      "text": "This means that as t\u2014> infinity both the dictionary and coefficients estimates converge to the true factors without incurring any bias.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          8,
          9
        ]
      ],
      "details": {}
    },
    {
      "review_id": "SJgzc8XTnX",
      "rebuttal_id": "SJxXh0Q1A7",
      "sentence_index": 18,
      "text": "We have added a clarification corresponding to this in the revised paper in Section 1.1 and after the statement of Theorem 1 in Section 3.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_mitigate-criticism",
      "alignment": [
        "context_sentences",
        [
          8,
          9
        ]
      ],
      "details": {}
    }
  ]
}