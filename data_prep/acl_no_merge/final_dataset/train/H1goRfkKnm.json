{
  "metadata": {
    "forum_id": "H1gR5iR5FX",
    "review_id": "H1goRfkKnm",
    "rebuttal_id": "HkxKS2FxR7",
    "title": "Analysing Mathematical Reasoning Abilities of Neural Models",
    "reviewer": "AnonReviewer3",
    "rating": 6,
    "conference": "ICLR2019",
    "permalink": "https://openreview.net/forum?id=H1gR5iR5FX&noteId=HkxKS2FxR7",
    "annotator": "anno2"
  },
  "review_sentences": [
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 0,
      "text": "Summary: This paper is about models for solving basic math problems.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 1,
      "text": "The main contribution is a synthetically generated dataset that includes a variety of types and difficulties of math problems; it is both larger and more varied than previous datasets of this type.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 2,
      "text": "The dataset is then used to evaluate a number of recurrent models (LSTM, LSTM+attention, transformer); these are very powerful models for general sequence-sequence tasks, but they are not explicitly tailored to math problems.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 3,
      "text": "The results are then analyzed and insights are derived explaining where neural models seemingly cope well with math tasks, and where they fall down.",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 4,
      "text": "Strengths: I am happy to see the proposal of a very large dataset with a lot of different axes for measuring and examining the performance of models.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_motivation-impact",
      "pol": "pol_positive"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 5,
      "text": "There are challenging desiderata involved in building the training+tests sets, and the authors have an interesting and involved methodology to accomplish these.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_motivation-impact",
      "pol": "pol_positive"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 6,
      "text": "The paper is very clearly written. I'm not aware of a comparable work, so the novelty here seems good.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 7,
      "text": "Weaknesses: The dataset created here is entirely synthetic, and the paper only includes one single small real-world case; it seems like it would be easy to generate a larger and more varied real world dataset as well (possibly from the large literature of extant solved problems in workbooks).",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_substance",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 8,
      "text": "It would have been useful to compare the general models here with some specific math problem-focused ones as well.",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_experiment",
      "asp": "asp_meaningful-comparison",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 9,
      "text": "Some details weren't clear to me.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 10,
      "text": "More in the comments below.",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 11,
      "text": "Verdict: I thought this was generally an interesting paper that has some very nice benefits, but also has some weaknesses that could be resolved. I view it as borderline, but I'm willing to change my mind based on the discussion.",
      "suffix": "\n\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 12,
      "text": "Comments:",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 13,
      "text": "- One area that could stand to be improved is prior work.",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_experiment",
      "asp": "asp_meaningful-comparison",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 14,
      "text": "I'd like to see more of a discussion of *prior data sets* rather than papers proposing models for problems.",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_experiment",
      "asp": "asp_meaningful-comparison",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 15,
      "text": "Since this is the core contribution, this should also be the main comparison.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 16,
      "text": "For example, EMLNP 2017 paper \"Deep Neural Solver for Math Word Problems\" mentions a size 60K problem dataset.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 17,
      "text": "A more extensive discussion will help convince the readers that the proposed dataset is indeed the largest and most diverse.",
      "suffix": "\n\n",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 18,
      "text": "- The authors note that previous datasets are often specific to one type of problem (i.e., single variable equation solving). Why not then combine multiple types of extant problem sets?",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_substance",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 19,
      "text": "- The authors divide dataset construction into crowdsourcing and synthetic.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_quote",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 20,
      "text": "This seems incomplete to me: there are tens of thousands (probably more) of exercises and problems available in workbooks for elementary, middle, and high school students.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_soundness-correctness",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 21,
      "text": "These are solved, and only require very limited validation.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 22,
      "text": "They are also categorized by difficulty and area.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 23,
      "text": "Presumably the cost here would be to physically scan some of these workbooks, but this seems like a very limited investment. Why not build datasets based on workbooks, problem solving books, etc?",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_substance",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 24,
      "text": "- How do are the difficulty levels synthetically determined?",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 25,
      "text": "- When generating the questions, the authors \"first sample the answer\". What's the distribution you use on the answer? This seems like it dramatically affects the resulting questions, so I'm curious how it's selected.",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 26,
      "text": "- The general methodology of generating questions and ensuring that no question is too rare or too frequent and the test set is sufficiently different---these are important questions and I commend the authors for providing a strong methodology.",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_edit",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 27,
      "text": "- I didn't understand the motivation for testing only very general-purpose models (this is described in Section 3).",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_substance",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 28,
      "text": "This is certainly a scientific decision, i.e., the authors are determining which models to use in order to determine the possible insights they will derive.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 29,
      "text": "But it's not clear to me why testing more sophisticated models that are tailored for math questions would *not* be useful.",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_clarification",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 30,
      "text": "In fact, assuming that such methods outperform general-purpose models, we could investigate why and where this is the case (in fact the proposed dataset is very useful for this).",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 31,
      "text": "On the other hand, if these specialized approaches largely fail to outperform general-purpose models, we would have the opposite insights---that these models' benefits are dataset-specific and thus limited.",
      "suffix": "\n\n",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 32,
      "text": "- Really would be good to do real-world tests in a more extensive way.",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_experiment",
      "asp": "asp_substance",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 33,
      "text": "A 40-question exam for 16 year olds is probably far too challenging for the current state of general recurrent models. Can you add some additional grades here, and more questions?",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_edit",
      "asp": "asp_substance",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 34,
      "text": "- For the number of thinkings steps, how does it scale up as you increase it from 0 to 16? Is there a clear relationships here?",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_clarity",
      "pol": "pol_neutral"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 35,
      "text": "- The 1+1+...+1 example is pretty intriguing, and could be a nice \"default\" question!",
      "suffix": "\n\n",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1goRfkKnm",
      "sentence_index": 36,
      "text": "- Minor typo: in the abstract: \"test spits\" should be \"test splits\"",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_typo",
      "asp": "asp_clarity",
      "pol": "pol_neutral"
    }
  ],
  "rebuttal_sentences": [
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 0,
      "text": "Thank you for pointing out the other datasets in algebraic word reasoning.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_structuring",
      "alignment": [
        "context_sentences",
        [
          7,
          8
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 1,
      "text": "We\u2019ve included these in an expanded discussion of related work with discussion on how they relate to the current dataset.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          7,
          8
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 2,
      "text": "Please let us know if we have missed other papers.",
      "suffix": "\n\n",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 3,
      "text": "Your proposal of combining multiple extant problem sets is a good idea.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_sentences",
        [
          18
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 4,
      "text": "We\u2019d want to ensure the combined datasets have a common format (e.g., the same unambiguous freeform text format for reasons of transferability, etc as argued in the paper), and there are interesting problem types occurring in other datasets (such as logical entailment or boolean satisfiability) that we haven\u2019t yet included.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_mitigate-criticism",
      "alignment": [
        "context_sentences",
        [
          18
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 5,
      "text": "We may in the future extend the dataset to include these other problem types if the current ones become solved, and of course we solicit contributions (in the form of generation code) to the dataset.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_future",
      "alignment": [
        "context_sentences",
        [
          18
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 6,
      "text": "We likely could not use workbooks etc as a source for problems without significant investment, since obtaining legal permission to redistribute copyrighted problems found in these books would probably be hard and/or expensive.",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-request",
      "alignment": [
        "context_sentences",
        [
          19,
          20,
          21,
          22,
          23
        ]
      ],
      "details": {
        "request_out_of_scope": false
      }
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 7,
      "text": "Having said that, it is definitely important to ensure the problems remain grounded in real-life problems (thus our small list of real-life exam questions).",
      "suffix": "",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          19,
          20,
          21,
          22,
          23
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 8,
      "text": "This was the motivation for testing trained models against \u201creal life\u201d questions occurring in school-level examinations; these questions are not intended to be a primary benchmark (with more questions and detailed grades), but rather simply a rough indication of whether training models to answer school-level questions could be achievable.",
      "suffix": "\n\n",
      "coarse": "dispute",
      "fine": "rebuttal_reject-criticism",
      "alignment": [
        "context_sentences",
        [
          19,
          20,
          21,
          22,
          23
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 9,
      "text": "On the distribution of the sampled answer (and the related question of how difficulty levels are determined), these are great questions.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_structuring",
      "alignment": [
        "context_sentences",
        [
          24,
          25
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 10,
      "text": "For some modules with two output choices (e.g., True, False), we can simply split the answers 50-50.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          24,
          25
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 11,
      "text": "But in general, the answer distribution depends on the module, with hand-tuning to ensure the (question, answer) pair is of a reasonable difficulty level as judged by humans.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          24,
          25
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 12,
      "text": "In more detail: as mentioned in the paper, we want to achieve upper bounds on the maximum probability that any single (question, answer) is sampled; thus if we sample the answer from a set of N possible answers, then to achieve a maximum probability p of a given question, the remaining choices made in generating the question must",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          24,
          25
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 13,
      "text": "be from a set of size p/N. We roughly aim to pick N (depending on p) so that conditioned on this, the question is as easy as possible; there is typically a hand-tuned sweet spot.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          24,
          25
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 14,
      "text": "On evaluating general-purpose models only, we may have phrased this badly in the paper, and have updated it.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          27,
          28,
          29,
          30,
          31
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 15,
      "text": "We are definitely interested in any models that learns to do mathematics and symbolic reasoning, which would include more sophisticated models tailored towards doing mathematics (one could imagine models with working memory, etc).",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          27,
          28,
          29,
          30,
          31
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 16,
      "text": "However, we discount models that already have their mathematics knowledge inbuilt rather than learnt (for example, this includes many of the models that occur in algebraic reasoning tasks, where the model learns to map the input text to an existing equation template, that is then solved by a fixed calculator).",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          27,
          28,
          29,
          30,
          31
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 17,
      "text": "We test DNC (differentiable neural computers) and RMC (relational memory core) models, which arguably are more specialized for doing mathematics, since they have a slot-based memory that may be appropriate for storing intermediate results.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          27,
          28,
          29,
          30,
          31
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 18,
      "text": "However these models obtained worse performance than the more general architectures, and we are not yet aware of models that are more tailored for doing mathematics that do not simply have their mathematics knowledge built-in and unlearnable; we hope the dataset will spur the development of new models along these lines.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          27,
          28,
          29,
          30,
          31
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 19,
      "text": "On the number of thinking steps, in our earlier analysis we trained up to 150k steps (compared with 500k for final performance reported in paper), and observed the following interpolation test performances by number of steps: 39% (0 steps), 46% (1 step), 48% (2), 49% (4), 50% (8), 51% (16).",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          34
        ]
      ],
      "details": {}
    },
    {
      "review_id": "H1goRfkKnm",
      "rebuttal_id": "HkxKS2FxR7",
      "sentence_index": 20,
      "text": "We are re-running experiments now to confirm the final performances, which we can include in the final paper.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_by-cr",
      "alignment": [
        "context_sentences",
        [
          34
        ]
      ],
      "details": {
        "manuscript_change": true
      }
    }
  ]
}