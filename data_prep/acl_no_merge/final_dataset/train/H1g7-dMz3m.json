{
  "metadata": {
    "forum_id": "HyGEM3C9KQ",
    "review_id": "H1g7-dMz3m",
    "rebuttal_id": "B1eovy5nam",
    "title": "Improving Differentiable Neural Computers Through Memory Masking, De-allocation, and Link Distribution Sharpness Control",
    "reviewer": "AnonReviewer1",
    "rating": 7,
    "conference": "ICLR2019",
    "permalink": "https://openreview.net/forum?id=HyGEM3C9KQ&noteId=B1eovy5nam",
    "annotator": "anno2"
  },
  "review_sentences": [
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 0,
      "text": "The authors propose three improvements to the DNC model: masked attention, erasion of de-allocated elements, and sharpened temporal links --- and show that this allows the model to solve synthetic memory tasks faster and with better precision.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 1,
      "text": "They also show the model performs better on average on bAbI than the original DNC.",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 2,
      "text": "The negatives are that the paper does not really show this modified DNC can solve a task that the original DNC could not. As the authors also admit, there have been other DNC improvements that have had more dramatic improvements on bAbI.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_negative"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 3,
      "text": "I think the paper is particularly clearly written, and I would vote for it being accepted as it has implications beyond the DNC.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_motivation-impact",
      "pol": "pol_positive"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 4,
      "text": "The fact that masked attention works so much better than the standard cosine-weighted content-based attention is pretty interesting in itself.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 5,
      "text": "The insights (e.g. Figure 5) are interesting and show the study is not just trying to be a benchmark paper for some top-level results, but actually cares about understanding a problem and fixing it.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_motivation-impact",
      "pol": "pol_positive"
    },
    {
      "review_id": "H1g7-dMz3m",
      "sentence_index": 6,
      "text": "Although most recent memory architectures do not seem to have incorporated the DNC's slightly complex memory de-allocation scheme, any resurgent work in this area would benefit from this study.",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    }
  ],
  "rebuttal_sentences": [
    {
      "review_id": "H1g7-dMz3m",
      "rebuttal_id": "B1eovy5nam",
      "sentence_index": 0,
      "text": "Thank you for your thoughtful feedback!",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    }
  ]
}