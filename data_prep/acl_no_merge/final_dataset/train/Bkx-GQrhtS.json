{
  "metadata": {
    "forum_id": "Ske31kBtPr",
    "review_id": "Bkx-GQrhtS",
    "rebuttal_id": "BkgqHnp_oS",
    "title": "Mathematical Reasoning in Latent Space",
    "reviewer": "AnonReviewer3",
    "rating": 8,
    "conference": "ICLR2020",
    "permalink": "https://openreview.net/forum?id=Ske31kBtPr&noteId=BkgqHnp_oS",
    "annotator": "anno10"
  },
  "review_sentences": [
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 0,
      "text": "The paper proposes a method to do math reasoning purely using formula embeddings.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 1,
      "text": "The proposed method employs a graph neural network to embed math formulas to a latent space.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 2,
      "text": "The formula embeddings are then combined with theorem embeddings (also formulas, computed in the same way as formula embeddings) to predict whether one can do one step of math reasoning using the corresponding theorem, and also to predict the embeddings of the resulting formula.",
      "suffix": "",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 3,
      "text": "Empirically the authors demonstrate that the method can be chained end-to-end to do multiple steps of reasoning purely in the latent space.",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_summary",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 4,
      "text": "I tend to accept this paper, (but also OK if it gets rejected), for the following reasons: (1) the idea is novel and interesting; (2) the writing of the paper is below conference standard and very hard to read, especially the method and the experiment sections.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 5,
      "text": "===========================================================================",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 6,
      "text": "Novelty and significance",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 7,
      "text": "I really like the idea of doing math reasoning in latent space.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 8,
      "text": "The idea is definitely novel and interesting.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 9,
      "text": "It is related to existing works such as neural logic induction[1] and planning in latent space[2].",
      "suffix": "",
      "coarse": "arg_fact",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 10,
      "text": "It is amazing that one can do multiple steps of math reasoning after only training the model using data from one single step.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_originality",
      "pol": "pol_positive"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 11,
      "text": "It would be interesting to see how it can improve existing learning-based theorem provers.",
      "suffix": "\n\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_substance",
      "pol": "pol_neutral"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 12,
      "text": "My question is if we want to integrate the proposed method into theorem provers, after multiple steps of math reasoning, how would us know the goal has been proved? Is it possible that we can train a decoder that maps back from the latent space to the formula space?",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 13,
      "text": "Also can it work with theorems that decompose the current goal into several sub-goals?",
      "suffix": "",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_soundness-correctness",
      "pol": "pol_neutral"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 14,
      "text": "I know these are not the concerns of this paper, but I would be really grateful if you could provide some intuitive answers!",
      "suffix": "\n\n",
      "coarse": "arg_social",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 15,
      "text": "===========================================================================",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 16,
      "text": "Writing",
      "suffix": "\n\n",
      "coarse": "arg_structuring",
      "fine": "arg-structuring_heading",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 17,
      "text": "The paper is not well-organized and not written in a consistent way. For the method and the experiment sections, I need to jump back and forth several times in order to understand what the authors are trying to say.",
      "suffix": "\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 18,
      "text": "1. Typo: Third paragraph in section 1, \"...which is makes use of ...\".",
      "suffix": "\n",
      "coarse": "arg_request",
      "fine": "arg-request_typo",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 19,
      "text": "2. It's very confusing when the authors introduce \\sigma and \\omega in the beginning of section 4: why would you need two networks predict the same thing?",
      "suffix": "\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 20,
      "text": "3. Mentioning \"merging \\sigma and \\omega, is left for future work\" is confusing before formally introducing \\sigma and \\omega.",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 21,
      "text": "4. Even when the authors formally introduce \\sigma and \\omega in 4.2, it is still not clear that why both of them are used for modelling the success probability.",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 22,
      "text": "5. In fact, I don't know why \\omega needs to output p. It's never mentioned in the experiment section.",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 23,
      "text": "6. The rationale of the two tower design (why not combine two) is not clearly explained.",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_replicability",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 24,
      "text": "7. Typo: Page 5 last paragraph, \"... negative instances for for each ...\".",
      "suffix": "\n",
      "coarse": "arg_request",
      "fine": "arg-request_typo",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 25,
      "text": "8. The itemized part in 5.3, \"...carefully selected baselines: 1.xxx, 2.xxx, 3. xxx, 4. xxx\". However, both 3 and 4 are not baselines!",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_soundness-correctness",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 26,
      "text": "9. It is not clear that baseline 1 and 2 correspond to which baselines in later experiments.",
      "suffix": "\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 27,
      "text": "10. Reading the baselines before the experiments is very confusing.",
      "suffix": "",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 28,
      "text": "For example, for baseline 1, it is very hard to understand why would we want to use such an unusual baseline, and why it is called a \"random baseline\".",
      "suffix": "\n",
      "coarse": "arg_request",
      "fine": "arg-request_explanation",
      "asp": "asp_replicability",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 29,
      "text": "11. Baseline 2 is actually referred to as \"usage baseline\" but this name is not introduced in the itemized part.",
      "suffix": "\n\n\n\n",
      "coarse": "arg_evaluative",
      "fine": "none",
      "asp": "asp_clarity",
      "pol": "pol_negative"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 30,
      "text": "[1] Rockt\u00e4schel, Tim, and Sebastian Riedel. \"End-to-end differentiable proving.\" Advances in Neural Information Processing Systems. 2017.",
      "suffix": "\n",
      "coarse": "arg_other",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    },
    {
      "review_id": "Bkx-GQrhtS",
      "sentence_index": 31,
      "text": "[2] Srinivas, Aravind, et al. \"Universal planning networks.\" arXiv preprint arXiv:1804.00645 (2018).",
      "suffix": "",
      "coarse": "arg_other",
      "fine": "none",
      "asp": "none",
      "pol": "none"
    }
  ],
  "rebuttal_sentences": [
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 0,
      "text": "We are thankful for the valuable feedback.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 1,
      "text": "The main concern of this review is the quality of the writing and experimental details.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_summary",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 2,
      "text": "We updated the paper to clarify all the names and ensure that all terms are introduced before they are used.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_global",
        null
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 3,
      "text": "The two tower design was necessary since the decision whether theorem T can be rewritten using parameters P requires both pieces of information, so we need to feed them to the network.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          23
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 4,
      "text": "In fact $\\omega$ does not need to predict p, but it gives extra supervision signal and therefore regularizes the prediction.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          23
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 5,
      "text": "The random baseline is necessary because of the unbalanced nature of the rewrite success, this is hard to control, so we added an extra baseline that shows that our results are better than just ignoring any of the input expressions (theorem or parameter).",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          28
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 6,
      "text": "In addition, we have simplified the architecture described in the paper by combining the networks $\\sigma$ and $\\omega$, and included the results from this architecture.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          19,
          20,
          21,
          22
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 7,
      "text": "We have significantly improved the experimental section by further clarifying the experiments and expanding them with more supporting measurements.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          17
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 8,
      "text": "We have also moved the two non-baselines out of the baselines section.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_done",
      "alignment": [
        "context_sentences",
        [
          26
        ]
      ],
      "details": {
        "request_out_of_scope": true
      }
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 9,
      "text": "Finally, thank you for the insightful questions!",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 10,
      "text": "With our current setup, the goal is to simply perform reasoning steps in latent space without specifically proving any statements.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          12
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 11,
      "text": "There are several approaches to make the network predict a closed goal, for example by predicting a fixed embedding such as the zero vector.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          12
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 12,
      "text": "We expect that most semantic aspects of the formula could be recovered, but not superficial features as the naming of the variables should not affect the rewriteability of formulas.",
      "suffix": "",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          12,
          13
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 13,
      "text": "The question how much of the formula can be recovered is probably dependent on the theorem database, since only those aspects that manifest in different rewrite successes are expected to be recovered.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_answer",
      "alignment": [
        "context_sentences",
        [
          12,
          13
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 14,
      "text": "We don't have much intuition on the decomposability of embeddings, but it seems like a fascinating research direction.",
      "suffix": "\n\n",
      "coarse": "concur",
      "fine": "rebuttal_future",
      "alignment": [
        "context_sentences",
        [
          12,
          13
        ]
      ],
      "details": {}
    },
    {
      "review_id": "Bkx-GQrhtS",
      "rebuttal_id": "BkgqHnp_oS",
      "sentence_index": 15,
      "text": "We are grateful for the feedback which has helped to make the paper much clearer and more readable.",
      "suffix": "",
      "coarse": "nonarg",
      "fine": "rebuttal_social",
      "alignment": [
        "context_global",
        null
      ],
      "details": {}
    }
  ]
}