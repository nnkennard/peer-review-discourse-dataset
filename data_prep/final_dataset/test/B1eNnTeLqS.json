{"metadata": {"forum_id": "Sklgs0NFvr", "review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "title": "Learning The Difference That Makes A Difference With Counterfactually-Augmented Data", "reviewer": "AnonReviewer4", "rating": 6, "conference": "ICLR2020", "permalink": "https://openreview.net/forum?id=Sklgs0NFvr&noteId=rke_9oPqir", "annotator": "anno0"}, "review_sentences": [{"review_id": "B1eNnTeLqS", "sentence_index": 0, "text": "This paper addresses the problem of building models for NLP tasks that are robust against spurious correlations in the data by introducing a human-in-the-loop method: annotators are asked to modify data-points minimally in order to change the label.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "B1eNnTeLqS", "sentence_index": 1, "text": "They refer to this process as counterfactual augmentation.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "B1eNnTeLqS", "sentence_index": 2, "text": "The authors apply this method to the IMDB sentiment dataset and to SNLI and show (among other things) that many models cannot generalize from the original dataset to the counterfactually-augmented one.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_motivation-impact", "pol": "pol_positive"}, {"review_id": "B1eNnTeLqS", "sentence_index": 3, "text": "This contribution is timely and addresses a very important problem that needs to be addressed in order to build more robust NLP systems.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_motivation-impact", "pol": "pol_positive"}, {"review_id": "B1eNnTeLqS", "sentence_index": 4, "text": "Because, however, of a few limitations, I recommend weak acceptance.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_soundness-correctness", "pol": "pol_neutral"}, {"review_id": "B1eNnTeLqS", "sentence_index": 5, "text": "My main hesitation comes from a lack of clarity about the main lesson we have learned.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 6, "text": "In particular, if the goal is to use this method to augment the data we use to train NLP systems in order to make them more robust, it seems that the time cost of the process will be prohibitive.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 7, "text": "On the other hand, perhaps these methods could be used to identify the kind of spurious correlations that models tend to rely on, which could then be used in a more automated data augmentation process.", "coarse": "arg_request", "fine": "arg-request_experiment", "asp": "asp_clarity", "pol": "pol_positive"}, {"review_id": "B1eNnTeLqS", "sentence_index": 8, "text": "If that's the goal, however, a more detailed error analysis would need to be included.", "coarse": "arg_request", "fine": "arg-request_experiment", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 9, "text": "A few small comments:", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "B1eNnTeLqS", "sentence_index": 10, "text": "* There was some analysis of the augmented IMDB dataset, but none of the SNLI dataset.", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 11, "text": "I would love to see a more detailed investigation of what annotators usually did.", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_clarity", "pol": "pol_neutral"}, {"review_id": "B1eNnTeLqS", "sentence_index": 12, "text": "For instance, a reason that hypothesis-only models do well is that certain words are very predictive of certain labels (e.g. \"not\" and contradiction).", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}, {"review_id": "B1eNnTeLqS", "sentence_index": 13, "text": "Do people leave the negations in when modifying such examples for entailment or neutrality, thus breaking the simple correspondence?", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 14, "text": "That's a very simple kind of question; more generally, I'd like to see more analysis of the new dataset.", "coarse": "arg_request", "fine": "arg-request_experiment", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 15, "text": "* The BiLSTM they use is very small (embedding and hidden dimension 50).", "coarse": "arg_request", "fine": "arg-request_edit", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 16, "text": "Given that BERT is most robust against their manipulation, it would be good to see a more powerful recurrent model for comparison.", "coarse": "arg_request", "fine": "arg-request_edit", "asp": "asp_meaningful-comparison", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 17, "text": "It would be easy to use ELMo here, if the main question is about Transformers vs recurrent models.", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 18, "text": "Some very minor / typographic comments:", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "B1eNnTeLqS", "sentence_index": 19, "text": "* abstract: \"with revise\" should be \"with revising\"", "coarse": "arg_request", "fine": "arg-request_typo", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 20, "text": "* first paragraph page 2: some references to causality literature and definition of spuriousness as common cause", "coarse": "arg_request", "fine": "arg-request_edit", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 21, "text": "* page 2, \"We show that...\" I'd break this into two sentences to make it easier to parse.", "coarse": "arg_request", "fine": "arg-request_typo", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "B1eNnTeLqS", "sentence_index": 22, "text": "* Table 3: I would make two columns for each model with accuracy on original versus revised.", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_clarity", "pol": "pol_positive"}, {"review_id": "B1eNnTeLqS", "sentence_index": 23, "text": "With the current table, one has to compare cells in the top half of the table to those in the bottom half of the table, which is quite difficult to do.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_clarity", "pol": "pol_negative"}], "rebuttal_sentences": [{"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 0, "text": "Thanks for the detailed and thoughtful review.", "coarse": "nonarg", "fine": "rebuttal_social", "alignment": ["context_global", null]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 1, "text": "We are glad that you think of this paper as a timely contribution addressing an important problem that must be addressed in order to build more robust NLP systems.", "coarse": "concur", "fine": "rebuttal_accept-praise", "alignment": ["context_global", null]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 2, "text": "We agree with your point that it would be great to have a practical takeaway guiding practitioners for what to do in practice.", "coarse": "concur", "fine": "rebuttal_accept-praise", "alignment": ["context_sentences", [2]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 3, "text": "We believe that the first step here is to characterize the problem coherently and that having laid this groundwork, one immediate next step is, as you suggest, to develop a more practical solution that requires a less expensive/onerous annotation effort.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 4, "text": "The key contribution of our paper is to provide a clear characterization of a variety of concerns in the language of interventions and to demonstrate that indeed, they can be addressed by acquiring interventional data.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 5, "text": "The knowledge that (i) NLP models trained on counterfactually augmented data suffer less from these problems and (ii) transport better out of sample (see new results in the updated draft, per R3\u2019s suggestion) validates this.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 6, "text": "As you mentioned, our solution requires significant expenditure (both financial and human capital)", "coarse": "concur", "fine": "rebuttal_concede-criticism", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 7, "text": "compared to simply labeling data", "coarse": "concur", "fine": "rebuttal_concede-criticism", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 8, "text": ".", "coarse": "concur", "fine": "rebuttal_concede-criticism", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 9, "text": "As a follow-up, for existing datasets, our next steps include investigating how to make these adjustments in a cost-effective way.", "coarse": "concur", "fine": "rebuttal_concede-criticism", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 10, "text": "In preliminary work, we have been investigating how to use humans in the loop more effectively.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 11, "text": "One approach involves using generative models to propose candidate substitutions and relying on humans only accept or reject the revisions (vs having to write them from scratch).", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 12, "text": "Our experience with crowdsourcing suggests that this feedback would be significantly cheaper to collect (provided that a reasonable fraction of suggestions were appropriate).", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 13, "text": "We additionally note that for some tasks, such as NLI, creating new datasets already requires annotators to synthesize examples de novo and the fractional increase for soliciting counterfactually-augmented data might not be as onerous as compared to tasks where the default is to rely on annotators only for tags.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [6, 7, 8]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 14, "text": "We are also appreciative of your constructive suggestions to improve the paper, and have taken several steps to improve the draft.", "coarse": "concur", "fine": "rebuttal_done", "alignment": ["context_sentences", [18]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 15, "text": "These include updating the draft to include (i) a detailed analysis of edits performed on SNLI, (ii) results on various datasets using an ELMo based classifier; (iii) concerning your question about larger Bi-LSTMs, we had tried a large Bi-LSTM but it overfit badly.", "coarse": "concur", "fine": "rebuttal_done", "alignment": ["context_sentences", [10, 11, 12, 13, 14, 15, 16, 17]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 16, "text": "We have updated the draft to include this detail.", "coarse": "concur", "fine": "rebuttal_done", "alignment": ["context_sentences", [10, 11, 12, 13, 14, 15, 16, 17]]}, {"review_id": "B1eNnTeLqS", "rebuttal_id": "rke_9oPqir", "sentence_index": 17, "text": "Thanks also for catching several typographic errors. We have addressed them in the new draft.", "coarse": "concur", "fine": "rebuttal_done", "alignment": ["context_sentences", [18, 19, 20, 21, 22, 23]]}]}