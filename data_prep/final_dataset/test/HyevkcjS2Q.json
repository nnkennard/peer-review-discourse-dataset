{"metadata": {"forum_id": "BJlMcjC5K7", "review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "title": "Neural Random Projections for Language Modelling", "reviewer": "AnonReviewer2", "rating": 3, "conference": "ICLR2019", "permalink": "https://openreview.net/forum?id=BJlMcjC5K7&noteId=HkxC23loAX", "annotator": "anno10"}, "review_sentences": [{"review_id": "HyevkcjS2Q", "sentence_index": 0, "text": "The main idea behind the paper is to use random projections as the initial word representations, rather than the vocab-size 1-hot representations, as is usually done in language modeling.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 1, "text": "The benefit is that the matrix which projects words into embedding space can then be much smaller, since the space of random projections can be much smaller than the vocab size.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 2, "text": "The idea is an interesting one, but this work is at too much of a preliminary stage for a top-tier conference such as ICLR. In its present state it would make for a potentially interesting paper at a targeted workshop.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_motivation-impact", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 4, "text": "More specific comments", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 5, "text": "--", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 6, "text": "The initial description of the language modeling problem assumes a particular decomposition of the joint probability, according to a particular application of the chain rule, but of course this is a modeling choice and not the only option (albeit the standard one).", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 7, "text": "The main problem with the paper is the use of simple baseline setups as the only experimental configuration:", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 8, "text": "o feedforward rather than recurrent network;", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 9, "text": "o use of the Penn Treebank dataset only;", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 10, "text": "o use of a small n for the n-grams.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 11, "text": "All or at least some of these decisions would need to be relaxed to make a convincing paper.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_substance", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 12, "text": "The reasons for the use of the energy-based formulation are not clear to me.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_replicability", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 13, "text": "Is the energy-based model particularly well-suited to the random-projection setup, or are there other reasons for using it, independent of the use of random projections?", "coarse": "arg_request", "fine": "arg-request_explanation", "asp": "asp_replicability", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 14, "text": "Just before equation 6 it says that the resulting vector representation is the *sum* of all the non-zero entries.", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}, {"review_id": "HyevkcjS2Q", "sentence_index": 15, "text": "But there are some minus ones in the random projection?", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 16, "text": "The PPL expression at the bottom of p.5 doesn't look right.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 17, "text": "The index over which the sum happens is n, but n is fixed? So this looks like a sum with just one component in it, namely the first n-gram.", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_replicability", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 18, "text": "It looks like all the results are given on the test set. Did you not do any tuning on the validation data?", "coarse": "arg_request", "fine": "arg-request_clarification", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 19, "text": "The plots in figure 4 are too small.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 20, "text": "It would be useful to have a table, like the one on the last page, which clearly shows the baseline vs. the random-projection model, with some description of the results in the main body of the text.", "coarse": "arg_request", "fine": "arg-request_result", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 21, "text": "The overall presentation could be better, and I would encourage the authors to tidy the paper up in any subsequent submission.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "HyevkcjS2Q", "sentence_index": 22, "text": "For example, there are lots of typos such as \"instead of trying to probability of a target word\".", "coarse": "arg_request", "fine": "arg-request_typo", "asp": "asp_clarity", "pol": "pol_negative"}], "rebuttal_sentences": [{"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 0, "text": "*All or at least some of these decisions would need to be relaxed to make a convincing paper.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [7, 8, 9, 10, 11]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 1, "text": "you are right, even if the focus of the paper is not on getting the best possible score on language modelling, different settings would make this point not only more convincing, but clearer.", "coarse": "concur", "fine": "rebuttal_concede-criticism", "alignment": ["context_sentences", [7, 8, 9, 10, 11]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 2, "text": "*The reasons for the use of the energy-based formulation are not clear to me.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [12]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 3, "text": "Is the energy-based model particularly well-suited to the random-projection setup, or are there other reasons for using it, independent of the use of random projections?", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [13]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 4, "text": "This formulation is fundamental for the next step of the work in which we are removing the restrictions from the output layer and learning word probability distributions without prior knowledge of the vocabulary size.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [12, 13]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 5, "text": "That said, the formulation is just the re-use of the embedding layer transposed.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [12, 13]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 6, "text": "It removed an entire set of m x V parameters and got us better results in all our experiments so we decided to use it.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [12, 13]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 7, "text": "* It looks like all the results are given on the test set. Did you not do any tuning on the validation data?", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [18]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 8, "text": "Yes, all the parameters were tuned on the validation data.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [18]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 9, "text": "All the models were selected according to their validation data evaluation.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [18]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 10, "text": "The early stop criterion is also based on the validation data evaluation.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [18]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 11, "text": "We consider the model to converge when it cannot improve further on validation data.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [18]]}, {"review_id": "HyevkcjS2Q", "rebuttal_id": "HkxC23loAX", "sentence_index": 12, "text": "The models never saw the test set during training or tuning, otherwise we would be cheating and these scores would be irrelevant to compare different settings.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [18]]}]}