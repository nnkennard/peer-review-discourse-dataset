{"metadata": {"forum_id": "r1eJssCqY7", "review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "title": "TabNN: A Universal Neural Network Solution for Tabular Data", "reviewer": "AnonReviewer3", "rating": 5, "conference": "ICLR2019", "permalink": "https://openreview.net/forum?id=r1eJssCqY7&noteId=HklpZu9eTm", "annotator": "anno0"}, "review_sentences": [{"review_id": "BkxIg3zKhX", "sentence_index": 0, "text": "The paper proposed an interesting algorithm and direction, which tries fill the gap of NN in tabular data learning.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_motivation-impact", "pol": "pol_positive"}, {"review_id": "BkxIg3zKhX", "sentence_index": 1, "text": "My concern is, given this is an empirical work,  the number of datasets used in evolution is a bit small.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_replicability", "pol": "pol_negative"}, {"review_id": "BkxIg3zKhX", "sentence_index": 2, "text": "Also, xgboost was the winning algorithm for many competitions for tabular data, would be good to compare the NN with properly optimised xgboost.", "coarse": "arg_request", "fine": "arg-request_experiment", "asp": "asp_meaningful-comparison", "pol": "pol_neutral"}, {"review_id": "BkxIg3zKhX", "sentence_index": 3, "text": "In chapter 2, related work.", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "BkxIg3zKhX", "sentence_index": 4, "text": "The authors state that \"tree-based models still yield two obvious shortages: (1) Hard to be integrated into complex end-to-end frameworks... (2) Hard to learn from streaming data.", "coarse": "arg_structuring", "fine": "arg-structuring_quote", "asp": "none", "pol": "none"}, {"review_id": "BkxIg3zKhX", "sentence_index": 5, "text": "To me these two reasoning statements are not particularly convincing. One could also say:", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_soundness-correctness", "pol": "pol_negative"}, {"review_id": "BkxIg3zKhX", "sentence_index": 6, "text": "NN models yield two obvious shortages: (1) Hard to be integrated into complex end-to-end frameworks... (2) Hard to learn from streaming data...", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}, {"review_id": "BkxIg3zKhX", "sentence_index": 7, "text": "Actually, tree ensemble based algorithms, eg Hoeffding tree ensembles, are among the best performed algorithms for data streaming tasks.", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}], "rebuttal_sentences": [{"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 0, "text": "Thanks for your efforts in reviewing our paper and the valuable comments.", "coarse": "nonarg", "fine": "rebuttal_social", "alignment": ["context_global", null]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 1, "text": "We attempt to address your concerns using the following points and hope they can help you better understand our work.", "coarse": "nonarg", "fine": "rebuttal_social", "alignment": ["context_global", null]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 2, "text": "1. the number of benchmark datasets", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [1]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 3, "text": "Currently, there are 5 datasets in our experiments.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [1]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 4, "text": "Actually, we have evaluated the proposed methods by conducting experiments in many datasets and observed the similar results.", "coarse": "dispute", "fine": "rebuttal_reject-criticism", "alignment": ["context_sentences", [1]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 5, "text": "Due to the space restriction, however, we cannot present them all in the paper.", "coarse": "dispute", "fine": "rebuttal_reject-request", "alignment": ["context_sentences", [1]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 6, "text": "We can provide more experiment results in appendix to eliminate this concern.", "coarse": "concur", "fine": "rebuttal_by-cr", "alignment": ["context_sentences", [1]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 7, "text": "2. XGBoost", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [2]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 8, "text": "We use LightGBM to learn GBDT model in the experiment part.", "coarse": "dispute", "fine": "rebuttal_mitigate-criticism", "alignment": ["context_sentences", [2]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 9, "text": "LightGBM is proven comparable (even better) with XGBoost in many Kaggle competitions (refer to https://www.kaggle.com/shivamb/data-science-trends-on-kaggle and https://github.com/Microsoft/LightGBM/tree/master/examples).", "coarse": "dispute", "fine": "rebuttal_mitigate-criticism", "alignment": ["context_sentences", [2]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 10, "text": "Therefore, we think using LightGBM is sufficient for comparison.", "coarse": "dispute", "fine": "rebuttal_mitigate-criticism", "alignment": ["context_sentences", [2]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 11, "text": "3. Two shortages of tree-based models", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 12, "text": "Let us describe these two shortages with more details here.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 13, "text": "1) Hard to be integrated into complex end-to-end frameworks.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 14, "text": "In such framework, there are many modules, each of which may correspond to one sub-task with a global optimization goal.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 15, "text": "The outputs of modules can serve as the inputs of other modules.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 16, "text": "Therefore, to train such a framework in an end-to-end way, the module should be able to propagate the errors from its outputs to its inputs.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 17, "text": "NN can naturally support this, as its learning algorithm is the back-propagation.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 18, "text": "In contrast, tree-based models do not support this as the tree learning process is not differentiable and therefore cannot propagate the errors to its inputs.", "coarse": "dispute", "fine": "rebuttal_contradict-assertion", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 19, "text": "As stated in the Section 2, although there are some works targeting to address this problem, these solutions will lose the automatic feature selection ability and cannot work well on the tabular data.", "coarse": "dispute", "fine": "rebuttal_contradict-assertion", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 20, "text": "2) Hard to learn from streaming data.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 21, "text": "For NN's learning, we can use Stochastic Gradient Descent (SGD) or mini-batch SGD to naturally learn from streaming data, since the NN model could be updated per data sample or per mini-batch of samples.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 22, "text": "However, it is not effective for tree-based model to support this as its learning needs the global statistical information.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 23, "text": "Using the partial statistical information may produce the sub-optimal split points and results in worse models.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 24, "text": "There are some works addressed this problem, like Hoeffding trees, which stores the statistical histograms into leaf nodes.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 25, "text": "However, most of these solutions are designed for the single decision tree.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 26, "text": "Although there are ensemble versions of them, most of them are based on bagging (like Random Forest), which is proven not as good as GBDT.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 27, "text": "In short, NN does not suffer from these two problems due to its mini-batch back-propagation learning process.", "coarse": "dispute", "fine": "rebuttal_reject-criticism", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 28, "text": "In contrast, tree-based model is hard to solve these two problems due to its learning algorithm is based on global statistical information.", "coarse": "dispute", "fine": "rebuttal_reject-criticism", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}, {"review_id": "BkxIg3zKhX", "rebuttal_id": "HklpZu9eTm", "sentence_index": 29, "text": "Therefore, TabNN is a better general solution for tabular data.", "coarse": "dispute", "fine": "rebuttal_reject-criticism", "alignment": ["context_sentences", [3, 4, 5, 6, 7]]}]}