{"metadata": {"forum_id": "SyVuRiC5K7", "review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "title": "LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING", "reviewer": "AnonReviewer2", "rating": 6, "conference": "ICLR2019", "permalink": "https://openreview.net/forum?id=SyVuRiC5K7&noteId=Hye0RIZ_RX", "annotator": "anno2"}, "review_sentences": [{"review_id": "S1x4ca-chQ", "sentence_index": 0, "text": "Summary", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 1, "text": "This paper proposes a meta-learning framework that leverages unlabeled data by learning the graph-based label propogation in an end-to-end manner.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 2, "text": "The proposed approaches are evaluated on two few-shot datasets and achieves the state-of-the-art results.", "coarse": "arg_structuring", "fine": "arg-structuring_summary", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 3, "text": "Pros.", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 4, "text": "-This paper is well-motivated.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_motivation-impact", "pol": "pol_positive"}, {"review_id": "S1x4ca-chQ", "sentence_index": 5, "text": "Studying label propagation in the meta-learning setting is interesting and novel.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_originality", "pol": "pol_positive"}, {"review_id": "S1x4ca-chQ", "sentence_index": 6, "text": "Intuitively, transductive label propagation should improve supervised learning when the number of labeled instances is low.", "coarse": "arg_fact", "fine": "none", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 7, "text": "-The empirical results show improvement over the baselines, which are expected.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_soundness-correctness", "pol": "pol_positive"}, {"review_id": "S1x4ca-chQ", "sentence_index": 8, "text": "Cons.", "coarse": "arg_structuring", "fine": "arg-structuring_heading", "asp": "none", "pol": "none"}, {"review_id": "S1x4ca-chQ", "sentence_index": 9, "text": "-Some technical details  are missing.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_clarity", "pol": "pol_negative"}, {"review_id": "S1x4ca-chQ", "sentence_index": 10, "text": "In Section 3.2.2, the authors only explain how they learn example-based \\sigma, but details on how to make graph construction end-to-end trainable are missing.", "coarse": "arg_evaluative", "fine": "none", "asp": "asp_replicability", "pol": "pol_negative"}, {"review_id": "S1x4ca-chQ", "sentence_index": 11, "text": "Constructing the full weight matrix requires the whole dataset as input and selecting k-nearest neighbor is a non-differentiable operation. Can you give more explanations?", "coarse": "arg_request", "fine": "arg-request_explanation", "asp": "asp_soundness-correctness", "pol": "pol_neutral"}, {"review_id": "S1x4ca-chQ", "sentence_index": 12, "text": "-Does episode training help label propagation? How about the results of label propagation without the episode training?", "coarse": "arg_request", "fine": "arg-request_explanation", "asp": "asp_clarity", "pol": "pol_neutral"}], "rebuttal_sentences": [{"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 0, "text": "Please refer to our main response in an above comment that addresses the primary and common questions amongst all reviewers.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_global", null]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 1, "text": "Here we respond to your specific comments.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_global", null]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 2, "text": "\"Some technical details are missing.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 3, "text": "In Section 3.2.2, the authors only explain how they learn example-based \\sigma, but details on how to make graph construction end-to-end trainable are missing.", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 4, "text": "Constructing the full weight matrix requires the whole dataset as input and selecting k-nearest neighbor is a non-differentiable operation. Can you give more explanations?\"", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 5, "text": ">>> Thanks for pointing out the details.", "coarse": "nonarg", "fine": "rebuttal_social", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 6, "text": "We want to clarify the few-shot setting.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 7, "text": "We follow the widely-used episodic paradigm proposed by Matching Networks [1].", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 8, "text": "In each episode (training batch), our algorithm solves a small classification problem which contains N classes each having K support and Q query examples (e.g., N=5, K=1, Q=15, totally 80 examples).", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 9, "text": "The weight matrix is constructed on the support and query examples in each episode rather than the whole dataset.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 10, "text": "This is very fast and efficient.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 11, "text": "In deep neural networks, there is a common trick in computing the gradient of operations non-differentiable at some points, but differentiable elsewhere, such as Max-Pooling (top-1) and top-k.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 12, "text": "In forward computation pass, the index position of the max (or top-k) values are stored.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 13, "text": "While in the back propagation pass, the gradient is computed only with respect to these saved positions.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 14, "text": "This trick is implemented in modern deep learning frameworks such as tensorflow and pytorch.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 15, "text": "In our paper, we use the tensorflow function tf.nn.top_k() to compute k-nearest neighbor operation.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [9, 10, 11]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 16, "text": "\"Does episode training help label propagation? How about the results of label propagation without the episode training? \"", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [12]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 17, "text": ">>> In our paper, the length scale parameter \\sigma is trained in an example-wise and episodic-wise way, as described in section 3.2.2 and Figure 4 of Appendix A. In order to investigate the benefit of episodic training, we combine the heuristic-based label propagation methods [2] with meta-learning to serve as a transductive baseline.", "coarse": "concur", "fine": "rebuttal_answer", "alignment": ["context_sentences", [12]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 18, "text": "Please refer to Table 1 and Table 2 line \"Label Propagation\".", "coarse": "nonarg", "fine": "rebuttal_structuring", "alignment": ["context_sentences", [12]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 19, "text": "It can be seen that TPN outperforms naive label propagation with a large margin, thus verifying the effectiveness of episode training.", "coarse": "nonarg", "fine": "rebuttal_summary", "alignment": ["context_sentences", [12]]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 20, "text": "[1] Vinyals, Oriol et al. \"Matching networks for one shot learning.\" NIPS. 2016.", "coarse": "nonarg", "fine": "rebuttal_other", "alignment": ["context_global", null]}, {"review_id": "S1x4ca-chQ", "rebuttal_id": "Hye0RIZ_RX", "sentence_index": 21, "text": "[2] Zhou, Denny et al. \"Learning with local and global consistency.\" NIPS. 2004.", "coarse": "nonarg", "fine": "rebuttal_other", "alignment": ["context_global", null]}]}