{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7008850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blerp(obj):\n",
    "    counter = collections.Counter()\n",
    "    for label in obj[\"reviewlabels\"]:\n",
    "        if label[\"merge-with-prior\"]:\n",
    "            continue\n",
    "        counter[label[\"labels\"][\"coarse\"]] += 1\n",
    "        counter[label[\"labels\"][\"asp\"]] += 1\n",
    "    for label in obj[\"rebuttallabels\"]:\n",
    "        counter[label[\"labels\"][\"coarseresponse\"]] += 1\n",
    "    return counter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17179d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "results = collections.OrderedDict()\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            subset_counter += blerp(train_obj)\n",
    "    results[subset] = subset_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b20dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "category_colors = plt.get_cmap('Pastel2')\n",
    "\n",
    "reb_category_names = \"concur dispute nonarg\".split()\n",
    "rev_category_names = \"Structuring Evaluative Request Fact Social Other\".split()\n",
    "asp_category_names = (\"Originality|Meaningful Comparison|Soundness/Correctness|\"\n",
    "                      \"Substance|Clarity|Motivation/Impact|Replicability\").split(\"|\")\n",
    "\n",
    "hatches = \"xx O // o ++ . \\\\\".split()\n",
    "\n",
    "def survey(results, category_names, ax, normalize=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    labels = list(results.keys())\n",
    "    labels = []\n",
    "    data = []\n",
    "    for label, value_map in results.items():\n",
    "        labels.append(label)\n",
    "        data.append([value_map[cat_name] for cat_name in category_names])\n",
    "    normalized_data = [[1000 * i/sum(l) for i in l] for l in data]\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    normalized_data = np.array(normalized_data)\n",
    "    normalized_data_cum = normalized_data.cumsum(axis=1)\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    if normalize:\n",
    "        ax.set_xlim(0, np.sum(normalized_data, axis=1).max())\n",
    "    else:\n",
    "        ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "    \n",
    "    for i, colname in enumerate(category_names):\n",
    "    \n",
    "        if normalize:\n",
    "            widths = normalized_data[:, i]\n",
    "            starts = normalized_data_cum[:, i] - widths\n",
    "        else:\n",
    "            widths = data[:, i]\n",
    "            starts = data_cum[:, i] - widths\n",
    "        rects = ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                        label=colname, color=category_colors(i), edgecolor='k', hatch=hatches[i])\n",
    "\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(0, -0.35, 1.0, 1.0),\n",
    "        loc='lower center', borderaxespad=0., ncol=2, fontsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 5))\n",
    "survey(results, rev_category_names, ax1, True)\n",
    "survey(results, asp_category_names, ax2, True)\n",
    "survey(results, reb_category_names, ax3, True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('dists.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreeability\n",
    "# For each example, list the ratio of concur v/s dispute as well as the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7613df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_responses = \"concur dispute nonarg\".split()\n",
    "Example = collections.namedtuple(\"Example\", [\"rating\", \"agreeableness\"])\n",
    "\n",
    "\n",
    "subset_dir = dataset_path + \"train/*\"\n",
    "examples = collections.defaultdict(list)\n",
    "\n",
    "def get_agreeableness(stance_counter):\n",
    "    return stance_counter[\"concur\"] / (stance_counter[\"concur\"] + stance_counter[\"dispute\"] + 1)\n",
    "\n",
    "for filename in glob.glob(subset_dir):\n",
    "    with open(filename, 'r') as f:\n",
    "        train_obj = json.load(f)\n",
    "        forum = train_obj['metadata']['forum_id']\n",
    "        rating = int(train_obj['metadata']['rating'].split(':')[0])\n",
    "        stance_counter = collections.Counter()\n",
    "        for label in train_obj[\"rebuttallabels\"]:\n",
    "            stance_counter[label['labels']['coarseresponse']] += 1\n",
    "        examples[forum].append(Example(rating, get_agreeableness(stance_counter)))\n",
    "\n",
    "ForumExample = collections.namedtuple(\"ForumExample\", \"index forum rating agreeableness\".split())\n",
    "forum_examples = []        \n",
    "forum_variability_map = {}\n",
    "for k, v in examples.items():\n",
    "    if len(v) == 3:\n",
    "        for comment in v:\n",
    "            forum_examples.append((k, comment.rating, comment.agreeableness))\n",
    "        forum_variability_map[k] = np.var([x.agreeableness for x in v])\n",
    "    \n",
    "# Reorder forums\n",
    "\n",
    "forum_order = {forum:i for i, (forum, _) in enumerate(sorted(forum_variability_map.items(), key=lambda x:x[1]))}\n",
    "\n",
    "examples_for_df = []\n",
    "for (forum, rating, agg) in forum_examples:\n",
    "    examples_for_df.append(ForumExample(forum_order[forum], forum, rating, agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(examples_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050692cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib.pyplot import figure\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.markers import MarkerStyle\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=80)\n",
    "colors = plt.get_cmap('magma_r')(np.linspace(0.1, 0.9, 10))\n",
    "custom_markers = []\n",
    "legend_words = []\n",
    "for rating in range(3, 10):\n",
    "    newdf = df[(df.rating == rating)]\n",
    "    plt.scatter(data=newdf, x=\"index\", y=\"agreeableness\", s=100, color=colors[rating], marker=(rating, 1, 0))\n",
    "    custom_markers.append(Line2D([0], [0], marker=(rating, 1, 0), color=colors[rating], lw=0))\n",
    "    legend_words.append(\"Rating: {0}\".format(rating))\n",
    "                          \n",
    "\n",
    "ax.set_xlabel('Forum index (in increasing order of agreeableness variance)', fontsize=18)\n",
    "ax.set_ylabel('Agreeableness', fontsize=18)\n",
    "ax.legend(custom_markers, legend_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('agreeability.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe just write a readme for the whole dataset?\n",
    "# What do people need to know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26b197",
   "metadata": {},
   "source": [
    "What are the things people want to know\n",
    "* How many forums\n",
    "* How many reviews in each forum. How many are double annotated. How long are they (in sentences). How long is each rebuttal (in sentences)\n",
    "* Plot with two plots on either side?\n",
    "* Split out ratings?\n",
    "\n",
    "* How to interpret no-pol v/s neutral-pol? how do these split v/s arg type\n",
    "\n",
    "* How many rebuttal sentences are mapped to something? How many review sentences are mapped to nothing?\n",
    "\n",
    "* Check for integrity of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbe3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "length_comparison_info = []\n",
    "LengthExample = collections.namedtuple(\"LengthExample\",\n",
    "                                       \"review_length rebuttal_length rating\".split())\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj['metadata']['forum_id']\n",
    "            examples.append(\n",
    "                LengthExample(len(train_obj['review']),\n",
    "                              len(train_obj['rebuttal'])/len(train_obj['review']),\n",
    "                             int(train_obj['metadata']['rating'].split(':')[0]))._asdict()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd46fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame.from_dict(examples)\n",
    "\n",
    "\n",
    "colors = plt.get_cmap('BuGn')(np.linspace(0.5, 0.9, 3))\n",
    "bins = [[3, 4], [5,6,7], [8,9,10]]\n",
    "\n",
    "for i, which_bin in enumerate(bins):\n",
    "    newdf = df[(df[\"rating\"].isin(which_bin))]\n",
    "    sns.kdeplot(data=newdf, x=\"review_length\",\n",
    "                color=colors[i],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f4512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reply_pairs = []\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            for rebuttal_label in train_obj[\"rebuttallabels\"]:\n",
    "                for aligned_review_i in rebuttal_label[\"labels\"][\"alignments\"]:\n",
    "                    reply_pairs.append((rebuttal_label[\"labels\"][\"responsetype\"],\n",
    "                                        train_obj[\"reviewlabels\"][aligned_review_i][\"labels\"][\"coarse\"]))\n",
    "c = collections.Counter(reply_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = \"subset forum rev_idx sent coarse fine asp pol merge\".split()\n",
    "RevSentLine = collections.namedtuple(\"RevSentLine\", fields)\n",
    "lines = []\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj[\"metadata\"][\"forum_id\"]\n",
    "            for sent, label in zip(train_obj[\"review\"], train_obj[\"reviewlabels\"]):\n",
    "                lines.append(RevSentLine(\n",
    "                    subset, forum, label[\"sid\"],\n",
    "                    sent[\"sentence\"],\n",
    "                label[\"labels\"][\"coarse\"],\n",
    "                label[\"labels\"][\"fine\"],\n",
    "                label[\"labels\"][\"asp\"],\n",
    "                label[\"labels\"][\"pol\"],\n",
    "                label[\"merge-with-prior\"]\n",
    "                )._asdict())\n",
    "import csv\n",
    "\n",
    "with open('review_sentences.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, fields, delimiter='\\t')\n",
    "    w.writeheader()\n",
    "    for row in lines:\n",
    "        w.writerow(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c863783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_checkers = collections.defaultdict(lambda:collections.Counter())\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj[\"metadata\"][\"forum_id\"]\n",
    "            \n",
    "            for sent, label in zip(train_obj[\"review\"], train_obj[\"reviewlabels\"]):\n",
    "                for label_type in \"fine asp pol\".split():\n",
    "                    label_checkers[label[\"labels\"][\"coarse\"]][label_type]\n",
    "                lines.append(RevSentLine(\n",
    "                    subset, forum, label[\"sid\"],\n",
    "                    sent[\"sentence\"],\n",
    "                label[\"labels\"][\"coarse\"],\n",
    "                label[\"labels\"][\"fine\"],\n",
    "                label[\"labels\"][\"asp\"],\n",
    "                label[\"labels\"][\"pol\"],\n",
    "                label[\"merge-with-prior\"]\n",
    "                )._asdict())\n",
    "\n",
    "vegetables = [\"cucumber\", \"tomato\", \"lettuce\", \"asparagus\",\n",
    "              \"potato\", \"wheat\", \"barley\"]\n",
    "farmers = [\"Farmer Joe\", \"Upland Bros.\", \"Smith Gardening\",\n",
    "           \"Agrifun\", \"Organiculture\", \"BioGoods Ltd.\", \"Cornylee Corp.\"]\n",
    "\n",
    "harvest = np.array([[0.8, 2.4, 2.5, 3.9, 0.0, 4.0, 0.0],\n",
    "                    [2.4, 0.0, 4.0, 1.0, 2.7, 0.0, 0.0],\n",
    "                    [1.1, 2.4, 0.8, 4.3, 1.9, 4.4, 0.0],\n",
    "                    [0.6, 0.0, 0.3, 0.0, 3.1, 0.0, 0.0],\n",
    "                    [0.7, 1.7, 0.6, 2.6, 2.2, 6.2, 0.0],\n",
    "                    [1.3, 1.2, 0.0, 0.0, 0.0, 3.2, 5.1],\n",
    "                    [0.1, 2.0, 0.0, 1.4, 0.0, 1.9, 6.3]])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(harvest)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(farmers)))\n",
    "ax.set_yticks(np.arange(len(vegetables)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(farmers)\n",
    "ax.set_yticklabels(vegetables)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(vegetables)):\n",
    "    for j in range(len(farmers)):\n",
    "        text = ax.text(j, i, harvest[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f41df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8baa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results[\"train\"].items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214896eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_globber = \"/Users/nnayak/Downloads/0517_split_2/train/*\"\n",
    "\n",
    "def review_getter(obj):\n",
    "    my_counter = collections.Counter()\n",
    "    for sent in obj[\"reviewlabels\"]:\n",
    "        my_counter[sent[\"labels\"][\"coarse\"]] += 1\n",
    "        my_counter[sent[\"labels\"][\"fine\"]] += 1\n",
    "        if sent[\"labels\"][\"asp\"]:\n",
    "            my_counter[sent[\"labels\"][\"asp\"]] += 1\n",
    "    return my_counter\n",
    "\n",
    "results = collections.Counter()\n",
    "review_counter = collections.Counter()\n",
    "for filename in glob.glob(dir_globber):\n",
    "    with open(filename, 'r') as f:\n",
    "        train_obj = json.load(f)\n",
    "        results += review_getter(train_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = collections.OrderedDict([\n",
    "    (\"Request\", \"Request Request.Typo Request.Edit Request.Clarification Request.Experiment Request.Explanation\".split()),\n",
    "    (\"Evaluative\", \"Evaluative|Clarity|Meaningful Comparison|Motivation/Impact|Originality|Replicability|Soundness/Correctness|Substance\".split(\"|\")),\n",
    "    (\"Structuring\", \"Structuring Structuring.Heading Structuring.Quote Structuring.Summary\".split()),\n",
    "    (\"Social\", [\"Social\"]),\n",
    "    (\"Fact\", [\"Fact\"]),\n",
    "    (\"Other\", [\"Other\"] ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99afe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "for i, (coarse, fines) in enumerate(b.items()):\n",
    "    for fine in fines:\n",
    "        dicts.append({\n",
    "            \"coarse\": coarse,\n",
    "            \"fine\": fine.split(\".\")[-1],\n",
    "            \"ct\": results[fine]\n",
    "        })\n",
    "    \n",
    "    dicts.append({\n",
    "        \"coarse\": \"\",\n",
    "        \"fine\": \" \" * i,\n",
    "        \"ct\": 0\n",
    "    })\n",
    "        \n",
    "d = pd.DataFrame.from_dict(dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "muted_palette = sns.color_palette('muted')\n",
    "dark_palette = sns.color_palette('dark')\n",
    "num_repeats = [7,9,5,2,2,2]\n",
    "\n",
    "my_palette = sum([[dark_palette[i]] + [muted_palette[i]] * (num-1) for i, num in enumerate(num_repeats)], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_cats = sns.barplot(x=np.array(d.fine), y=np.array(d.ct), palette=my_palette)\n",
    "_ = plt.xticks(rotation=60, ha='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca39eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "source_counter = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            if train_obj['metadata']['anno'] == 'anno0' and not subset == 'train':\n",
    "                final_subset = subset + \"_adjudicated\"\n",
    "            else:\n",
    "                final_subset = subset\n",
    "            source_counter[final_subset][train_obj[\"metadata\"]['conference']] += 1\n",
    "            \n",
    "print(source_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "\n",
    "for subset, v in source_counter.items():\n",
    "    for conference, count in v.items():\n",
    "        dicts.append({\n",
    "            \"subset\": subset.split('_')[0],\n",
    "            \"conference\": conference,\n",
    "            \"total\": count,\n",
    "            \"adjudicated\": 'Y' if 'adjudicated' in subset else 'N',\n",
    "        })\n",
    "    \n",
    "f = pd.DataFrame.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(f, index='conference', columns=['subset', 'adjudicated'], values='total',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d060d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "\n",
    "guest_client = openreview.Client(baseurl='https://api.openreview.net')\n",
    "\n",
    "def get_num_reviews(guest_client, forum_id):\n",
    "    forum_notes = guest_client.get_notes(forum=forum_id)\n",
    "    review_count = 0\n",
    "    for note in forum_notes:\n",
    "        if note.replyto == forum_id and 'Reviewer' in note.signatures[0]:\n",
    "            review_count += 1\n",
    "    return review_count\n",
    "\n",
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "source_counter = collections.defaultdict(\n",
    "    lambda: collections.defaultdict(list))\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            key = (train_obj['metadata']['forum_id']\n",
    "                ,train_obj['metadata']['conference'])\n",
    "            source_counter[subset][key].append(\n",
    "            train_obj['metadata']['review'])\n",
    "dicts = []            \n",
    "for subset, examples in source_counter.items():\n",
    "    print(subset)\n",
    "    print(len(examples))\n",
    "#     for (forum, conference), reviews in examples.items():\n",
    "#         dicts.append(\n",
    "#         {\"forum\": forum,\n",
    "#          \"subset\": subset,\n",
    "#          \"conference\": conference,\n",
    "#          \"annotated_reviews\": len(reviews),\n",
    "#          \"total_reviews\":  get_num_reviews(guest_client, forum)})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dicts)\n",
    "df[\"unannotated\"] = df.total_reviews - df.annotated_reviews\n",
    "df2 = df.sort_values(by=[\"subset\", 'unannotated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ac185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(stacked=True, x=\"forum\", y=[\"annotated_reviews\", \"unannotated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7342cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e901e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a3766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
