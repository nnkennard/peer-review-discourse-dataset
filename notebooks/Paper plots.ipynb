{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70205132",
   "metadata": {},
   "source": [
    "All moved to [notebook](https://github.com/nnkennard/lab-notebook/blob/master/08/2021-08-14.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7008850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3aa5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blerp(obj):\n",
    "    counter = collections.Counter()\n",
    "    for label in obj[\"reviewlabels\"]:\n",
    "        if label[\"merge-with-prior\"]:\n",
    "            continue\n",
    "        counter[label[\"labels\"][\"coarse\"]] += 1\n",
    "        counter[label[\"labels\"][\"asp\"]] += 1\n",
    "    for label in obj[\"rebuttallabels\"]:\n",
    "        counter[label[\"labels\"][\"coarseresponse\"]] += 1\n",
    "    return counter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17179d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "results = collections.OrderedDict()\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            subset_counter += blerp(train_obj)\n",
    "    results[subset] = subset_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b20dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "category_colors = plt.get_cmap('Pastel2')\n",
    "\n",
    "reb_category_names = \"concur dispute nonarg\".split()\n",
    "rev_category_names = \"Structuring Evaluative Request Fact Social Other\".split()\n",
    "asp_category_names = (\"Originality|Meaningful Comparison|Soundness/Correctness|\"\n",
    "                      \"Substance|Clarity|Motivation/Impact|Replicability\").split(\"|\")\n",
    "\n",
    "hatches = \"xx O // o ++ . \\\\\".split()\n",
    "\n",
    "def survey(results, category_names, ax, normalize=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    labels = list(results.keys())\n",
    "    labels = []\n",
    "    data = []\n",
    "    for label, value_map in results.items():\n",
    "        labels.append(label)\n",
    "        data.append([value_map[cat_name] for cat_name in category_names])\n",
    "    normalized_data = [[1000 * i/sum(l) for i in l] for l in data]\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    normalized_data = np.array(normalized_data)\n",
    "    normalized_data_cum = normalized_data.cumsum(axis=1)\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    if normalize:\n",
    "        ax.set_xlim(0, np.sum(normalized_data, axis=1).max())\n",
    "    else:\n",
    "        ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "    \n",
    "    for i, colname in enumerate(category_names):\n",
    "    \n",
    "        if normalize:\n",
    "            widths = normalized_data[:, i]\n",
    "            starts = normalized_data_cum[:, i] - widths\n",
    "        else:\n",
    "            widths = data[:, i]\n",
    "            starts = data_cum[:, i] - widths\n",
    "        rects = ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                        label=colname, color=category_colors(i), edgecolor='k', hatch=hatches[i])\n",
    "\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(0, -0.35, 1.0, 1.0),\n",
    "        loc='lower center', borderaxespad=0., ncol=2, fontsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5765d9c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-795cce87aca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msurvey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_category_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msurvey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masp_category_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msurvey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreb_category_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-02479801ccd3>\u001b[0m in \u001b[0;36msurvey\u001b[0;34m(results, category_names, ax, normalize)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnormalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-02479801ccd3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnormalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-02479801ccd3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnormalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 5))\n",
    "survey(results, rev_category_names, ax1, True)\n",
    "survey(results, asp_category_names, ax2, True)\n",
    "survey(results, reb_category_names, ax3, True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('dists.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreeability\n",
    "# For each example, list the ratio of concur v/s dispute as well as the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7613df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_responses = \"concur dispute nonarg\".split()\n",
    "Example = collections.namedtuple(\"Example\", [\"rating\", \"agreeableness\"])\n",
    "\n",
    "\n",
    "subset_dir = dataset_path + \"train/*\"\n",
    "examples = collections.defaultdict(list)\n",
    "\n",
    "def get_agreeableness(stance_counter):\n",
    "    return stance_counter[\"concur\"] / (stance_counter[\"concur\"] + stance_counter[\"dispute\"] + 1)\n",
    "\n",
    "for filename in glob.glob(subset_dir):\n",
    "    with open(filename, 'r') as f:\n",
    "        train_obj = json.load(f)\n",
    "        forum = train_obj['metadata']['forum_id']\n",
    "        rating = int(train_obj['metadata']['rating'].split(':')[0])\n",
    "        stance_counter = collections.Counter()\n",
    "        for label in train_obj[\"rebuttallabels\"]:\n",
    "            stance_counter[label['labels']['coarseresponse']] += 1\n",
    "        examples[forum].append(Example(rating, get_agreeableness(stance_counter)))\n",
    "\n",
    "ForumExample = collections.namedtuple(\"ForumExample\", \"index forum rating agreeableness\".split())\n",
    "forum_examples = []        \n",
    "forum_variability_map = {}\n",
    "for k, v in examples.items():\n",
    "    if len(v) == 3:\n",
    "        for comment in v:\n",
    "            forum_examples.append((k, comment.rating, comment.agreeableness))\n",
    "        forum_variability_map[k] = np.var([x.agreeableness for x in v])\n",
    "    \n",
    "# Reorder forums\n",
    "\n",
    "forum_order = {forum:i for i, (forum, _) in enumerate(sorted(forum_variability_map.items(), key=lambda x:x[1]))}\n",
    "\n",
    "examples_for_df = []\n",
    "for (forum, rating, agg) in forum_examples:\n",
    "    examples_for_df.append(ForumExample(forum_order[forum], forum, rating, agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(examples_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050692cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib.pyplot import figure\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.markers import MarkerStyle\n",
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=80)\n",
    "colors = plt.get_cmap('magma_r')(np.linspace(0.1, 0.9, 10))\n",
    "custom_markers = []\n",
    "legend_words = []\n",
    "for rating in range(3, 10):\n",
    "    newdf = df[(df.rating == rating)]\n",
    "    plt.scatter(data=newdf, x=\"index\", y=\"agreeableness\", s=100, color=colors[rating], marker=(rating, 1, 0))\n",
    "    custom_markers.append(Line2D([0], [0], marker=(rating, 1, 0), color=colors[rating], lw=0))\n",
    "    legend_words.append(\"Rating: {0}\".format(rating))\n",
    "                          \n",
    "\n",
    "ax.set_xlabel('Forum index (in increasing order of agreeableness variance)', fontsize=18)\n",
    "ax.set_ylabel('Agreeableness', fontsize=18)\n",
    "ax.legend(custom_markers, legend_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('agreeability.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe just write a readme for the whole dataset?\n",
    "# What do people need to know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26b197",
   "metadata": {},
   "source": [
    "What are the things people want to know\n",
    "* How many forums\n",
    "* How many reviews in each forum. How many are double annotated. How long are they (in sentences). How long is each rebuttal (in sentences)\n",
    "* Plot with two plots on either side?\n",
    "* Split out ratings?\n",
    "\n",
    "* How to interpret no-pol v/s neutral-pol? how do these split v/s arg type\n",
    "\n",
    "* How many rebuttal sentences are mapped to something? How many review sentences are mapped to nothing?\n",
    "\n",
    "* Check for integrity of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbe3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "length_comparison_info = []\n",
    "LengthExample = collections.namedtuple(\"LengthExample\",\n",
    "                                       \"review_length rebuttal_length rating\".split())\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj['metadata']['forum_id']\n",
    "            examples.append(\n",
    "                LengthExample(len(train_obj['review']),\n",
    "                              len(train_obj['rebuttal'])/len(train_obj['review']),\n",
    "                             int(train_obj['metadata']['rating'].split(':')[0]))._asdict()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd46fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame.from_dict(examples)\n",
    "\n",
    "\n",
    "colors = plt.get_cmap('BuGn')(np.linspace(0.5, 0.9, 3))\n",
    "bins = [[3, 4], [5,6,7], [8,9,10]]\n",
    "\n",
    "for i, which_bin in enumerate(bins):\n",
    "    newdf = df[(df[\"rating\"].isin(which_bin))]\n",
    "    sns.kdeplot(data=newdf, x=\"review_length\",\n",
    "                color=colors[i],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f4512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reply_pairs = []\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            for rebuttal_label in train_obj[\"rebuttallabels\"]:\n",
    "                for aligned_review_i in rebuttal_label[\"labels\"][\"alignments\"]:\n",
    "                    reply_pairs.append((rebuttal_label[\"labels\"][\"responsetype\"],\n",
    "                                        train_obj[\"reviewlabels\"][aligned_review_i][\"labels\"][\"coarse\"]))\n",
    "c = collections.Counter(reply_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = \"subset forum rev_idx sent coarse fine asp pol merge\".split()\n",
    "RevSentLine = collections.namedtuple(\"RevSentLine\", fields)\n",
    "lines = []\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj[\"metadata\"][\"forum_id\"]\n",
    "            for sent, label in zip(train_obj[\"review\"], train_obj[\"reviewlabels\"]):\n",
    "                lines.append(RevSentLine(\n",
    "                    subset, forum, label[\"sid\"],\n",
    "                    sent[\"sentence\"],\n",
    "                label[\"labels\"][\"coarse\"],\n",
    "                label[\"labels\"][\"fine\"],\n",
    "                label[\"labels\"][\"asp\"],\n",
    "                label[\"labels\"][\"pol\"],\n",
    "                label[\"merge-with-prior\"]\n",
    "                )._asdict())\n",
    "import csv\n",
    "\n",
    "with open('review_sentences.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, fields, delimiter='\\t')\n",
    "    w.writeheader()\n",
    "    for row in lines:\n",
    "        w.writerow(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c863783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_checkers = collections.defaultdict(lambda:collections.Counter())\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            forum = train_obj[\"metadata\"][\"forum_id\"]\n",
    "            \n",
    "            for sent, label in zip(train_obj[\"review\"], train_obj[\"reviewlabels\"]):\n",
    "                for label_type in \"fine asp pol\".split():\n",
    "                    label_checkers[label[\"labels\"][\"coarse\"]][label_type]\n",
    "                lines.append(RevSentLine(\n",
    "                    subset, forum, label[\"sid\"],\n",
    "                    sent[\"sentence\"],\n",
    "                label[\"labels\"][\"coarse\"],\n",
    "                label[\"labels\"][\"fine\"],\n",
    "                label[\"labels\"][\"asp\"],\n",
    "                label[\"labels\"][\"pol\"],\n",
    "                label[\"merge-with-prior\"]\n",
    "                )._asdict())\n",
    "\n",
    "vegetables = [\"cucumber\", \"tomato\", \"lettuce\", \"asparagus\",\n",
    "              \"potato\", \"wheat\", \"barley\"]\n",
    "farmers = [\"Farmer Joe\", \"Upland Bros.\", \"Smith Gardening\",\n",
    "           \"Agrifun\", \"Organiculture\", \"BioGoods Ltd.\", \"Cornylee Corp.\"]\n",
    "\n",
    "harvest = np.array([[0.8, 2.4, 2.5, 3.9, 0.0, 4.0, 0.0],\n",
    "                    [2.4, 0.0, 4.0, 1.0, 2.7, 0.0, 0.0],\n",
    "                    [1.1, 2.4, 0.8, 4.3, 1.9, 4.4, 0.0],\n",
    "                    [0.6, 0.0, 0.3, 0.0, 3.1, 0.0, 0.0],\n",
    "                    [0.7, 1.7, 0.6, 2.6, 2.2, 6.2, 0.0],\n",
    "                    [1.3, 1.2, 0.0, 0.0, 0.0, 3.2, 5.1],\n",
    "                    [0.1, 2.0, 0.0, 1.4, 0.0, 1.9, 6.3]])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(harvest)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(farmers)))\n",
    "ax.set_yticks(np.arange(len(vegetables)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(farmers)\n",
    "ax.set_yticklabels(vegetables)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(vegetables)):\n",
    "    for j in range(len(farmers)):\n",
    "        text = ax.text(j, i, harvest[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f41df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8baa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results[\"train\"].items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214896eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_globber = \"/Users/nnayak/Downloads/0517_split_2/train/*\"\n",
    "\n",
    "def review_getter(obj):\n",
    "    my_counter = collections.Counter()\n",
    "    for sent in obj[\"reviewlabels\"]:\n",
    "        my_counter[sent[\"labels\"][\"coarse\"]] += 1\n",
    "        my_counter[sent[\"labels\"][\"fine\"]] += 1\n",
    "        if sent[\"labels\"][\"asp\"]:\n",
    "            my_counter[sent[\"labels\"][\"asp\"]] += 1\n",
    "    return my_counter\n",
    "\n",
    "results = collections.Counter()\n",
    "review_counter = collections.Counter()\n",
    "for filename in glob.glob(dir_globber):\n",
    "    with open(filename, 'r') as f:\n",
    "        train_obj = json.load(f)\n",
    "        results += review_getter(train_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = collections.OrderedDict([\n",
    "    (\"Request\", \"Request Request.Typo Request.Edit Request.Clarification Request.Experiment Request.Explanation\".split()),\n",
    "    (\"Evaluative\", \"Evaluative|Clarity|Meaningful Comparison|Motivation/Impact|Originality|Replicability|Soundness/Correctness|Substance\".split(\"|\")),\n",
    "    (\"Structuring\", \"Structuring Structuring.Heading Structuring.Quote Structuring.Summary\".split()),\n",
    "    (\"Social\", [\"Social\"]),\n",
    "    (\"Fact\", [\"Fact\"]),\n",
    "    (\"Other\", [\"Other\"] ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99afe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "for i, (coarse, fines) in enumerate(b.items()):\n",
    "    for fine in fines:\n",
    "        dicts.append({\n",
    "            \"coarse\": coarse,\n",
    "            \"fine\": fine.split(\".\")[-1],\n",
    "            \"ct\": results[fine]\n",
    "        })\n",
    "    \n",
    "    dicts.append({\n",
    "        \"coarse\": \"\",\n",
    "        \"fine\": \" \" * i,\n",
    "        \"ct\": 0\n",
    "    })\n",
    "        \n",
    "d = pd.DataFrame.from_dict(dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "muted_palette = sns.color_palette('muted')\n",
    "dark_palette = sns.color_palette('dark')\n",
    "num_repeats = [7,9,5,2,2,2]\n",
    "\n",
    "my_palette = sum([[dark_palette[i]] + [muted_palette[i]] * (num-1) for i, num in enumerate(num_repeats)], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_cats = sns.barplot(x=np.array(d.fine), y=np.array(d.ct), palette=my_palette)\n",
    "_ = plt.xticks(rotation=60, ha='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca39eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "source_counter = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            if train_obj['metadata']['anno'] == 'anno0' and not subset == 'train':\n",
    "                final_subset = subset + \"_adjudicated\"\n",
    "            else:\n",
    "                final_subset = subset\n",
    "            source_counter[final_subset][train_obj[\"metadata\"]['conference']] += 1\n",
    "            \n",
    "print(source_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "\n",
    "for subset, v in source_counter.items():\n",
    "    for conference, count in v.items():\n",
    "        dicts.append({\n",
    "            \"subset\": subset.split('_')[0],\n",
    "            \"conference\": conference,\n",
    "            \"total\": count,\n",
    "            \"adjudicated\": 'Y' if 'adjudicated' in subset else 'N',\n",
    "        })\n",
    "    \n",
    "f = pd.DataFrame.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(f, index='conference', columns=['subset', 'adjudicated'], values='total',aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d060d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "\n",
    "guest_client = openreview.Client(baseurl='https://api.openreview.net')\n",
    "\n",
    "def get_num_reviews(guest_client, forum_id):\n",
    "    forum_notes = guest_client.get_notes(forum=forum_id)\n",
    "    review_count = 0\n",
    "    for note in forum_notes:\n",
    "        if note.replyto == forum_id and 'Reviewer' in note.signatures[0]:\n",
    "            review_count += 1\n",
    "    return review_count\n",
    "\n",
    "dataset_path = \"/Users/nnayak/Downloads/0517_split_2/\"\n",
    "\n",
    "source_counter = collections.defaultdict(\n",
    "    lambda: collections.defaultdict(list))\n",
    "\n",
    "for subset in \"train dev test\".split():\n",
    "    subset_dir = dataset_path + subset + \"/*\"\n",
    "    subset_counter = collections.Counter()\n",
    "    for filename in glob.glob(subset_dir):\n",
    "        with open(filename, 'r') as f:\n",
    "            train_obj = json.load(f)\n",
    "            key = (train_obj['metadata']['forum_id']\n",
    "                ,train_obj['metadata']['conference'])\n",
    "            source_counter[subset][key].append(\n",
    "            train_obj['metadata']['review'])\n",
    "dicts = []            \n",
    "for subset, examples in source_counter.items():\n",
    "    print(subset)\n",
    "    print(len(examples))\n",
    "    for (forum, conference), reviews in examples.items():\n",
    "        dicts.append(\n",
    "        {\"forum\": forum,\n",
    "         \"subset\": subset,\n",
    "         \"conference\": conference,\n",
    "         \"annotated_reviews\": len(reviews),\n",
    "         \"total_reviews\":  get_num_reviews(guest_client, forum)})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dicts)\n",
    "df[\"unannotated\"] = df.total_reviews - df.annotated_reviews\n",
    "df2 = df.sort_values(by=[\"subset\", 'unannotated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ac185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(stacked=True, x=\"forum\", y=[\"annotated_reviews\", \"unannotated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7342cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e901e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a3766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
