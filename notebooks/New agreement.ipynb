{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "from pyannote.core import Segment\n",
    "from pygamma_agreement import (CombinedCategoricalDissimilarity,\n",
    "                               Continuum,\n",
    "                               show_alignment,\n",
    "                               show_continuum)\n",
    "\n",
    "def get_metadata(annotation, key):\n",
    "    return annotation[\"metadata\"][key]\n",
    "\n",
    "def get_pair_identifier(anno1, anno2):\n",
    "    assert get_metadata(anno1, \"review_id\") == get_metadata(anno2, \"review_id\")    \n",
    "    anno_names_in_order = sorted([get_metadata(anno1, \"annotator\"),\n",
    "                                  get_metadata(anno2, \"annotator\")])\n",
    "    return \"|\".join([get_metadata(anno1, \"review_id\")] + anno_names_in_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers for gamma ===\n",
    "\n",
    "def get_contiguous_segments(aligned_indices):\n",
    "    \"\"\"\n",
    "        Segments a list of indices into a list of lists, where each sub-list contains a contiguous subsequence of indices.\n",
    "    \"\"\"\n",
    "    assert aligned_indices == list(sorted(aligned_indices))\n",
    "    segments = []\n",
    "    l = list(aligned_indices)\n",
    "    current_segment = []\n",
    "    while l:\n",
    "        k = l.pop(0)\n",
    "        if current_segment:\n",
    "            if k == current_segment[-1] + 1:\n",
    "                current_segment.append(k)\n",
    "            else:\n",
    "                segments.append(current_segment)\n",
    "                current_segment = [k]\n",
    "        else:\n",
    "            current_segment = [k]\n",
    "    segments.append(current_segment)\n",
    "    return segments\n",
    "\n",
    "print(\"Testing get_contiguous_segments\")\n",
    "tgcs_input = [1,2,3,6,7,9,11,12]\n",
    "print(\"Input:\", tgcs_input)\n",
    "print(\"Output:\", get_contiguous_segments(tgcs_input))\n",
    "\n",
    "def get_continuum_items_and_categories(rebuttal_sentences, annotator, key):\n",
    "    \"\"\"\n",
    "        Given rebuttal sentences and the annotator name, produces items for continuum for gamma calculation\n",
    "        \n",
    "        Returns 3-tuples, of the format:\n",
    "            (<annotator_id>, Segment(<segment_start>, <segment_exclusive_end>), <rebuttal_label>) # TODO(TJO): Is exclusive end correct?\n",
    "        as well as a set of all possible rebuttal labels for this example # TODO(TJO): Does it matter if it's all possible labels or all labels which are present?\n",
    "    \"\"\"\n",
    "    categories = set()\n",
    "    new_continuum_items = []\n",
    "    for i, sentence in enumerate(rebuttal_sentences):\n",
    "        category = sentence[key]\n",
    "        align_type, align_indices = sentence[\"alignment\"]\n",
    "        if align_indices is not None:\n",
    "            segments = get_contiguous_segments(align_indices) # TODO(TJO): Is this the right way to get segments from alignments?\n",
    "            for segment in segments:\n",
    "                new_continuum_items.append((annotator, Segment(segment[0], segment[-1] + 1), category))\n",
    "                categories.add(category)\n",
    "    \n",
    "    return new_continuum_items, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7881649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers for kappa ===\n",
    "\n",
    "REV_LABELS = \"coarse fine asp pol\".split()\n",
    "REB_LABELS = \"coarse fine\".split()\n",
    "\n",
    "LABEL_TYPES = [\"rev_\"+label\n",
    "               for label in REV_LABELS] + [\"reb_\"+label\n",
    "                for label in REB_LABELS]\n",
    "                                  \n",
    "def get_label_lists(annotation):\n",
    "    \n",
    "    label_lists = {\n",
    "        label:[] for label in LABEL_TYPES\n",
    "    }\n",
    "    \n",
    "    for rev_label in REV_LABELS:\n",
    "        for sentence in annotation[\"review_sentences\"]:\n",
    "            label_lists[\"rev_\" + rev_label].append(sentence[rev_label])\n",
    "    for reb_label in REB_LABELS:\n",
    "        for sentence in annotation[\"rebuttal_sentences\"]:\n",
    "            label_lists[\"reb_\" + reb_label].append(sentence[reb_label])\n",
    "    return label_lists\n",
    "\n",
    "def get_kappas_from_label_lists(anno_a, anno_b):\n",
    "    kappa_map = {}\n",
    "    for label, values_a in anno_a.items():\n",
    "        if len(values_a) == len(anno_b[label]):\n",
    "            values_b = anno_b[label]\n",
    "            kappa_map[label] = kappa(values_a, values_b)\n",
    "        else:\n",
    "            kappa_map[label] = None\n",
    "    return kappa_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Retrieve annotations\n",
    "\n",
    "annotation_map = collections.defaultdict(dict)\n",
    "\n",
    "for filename in glob.glob(\"../data_prep/final_dataset/test/*\"):\n",
    "    with open(filename, 'r') as f:\n",
    "        p = json.load(f)\n",
    "        annotator = get_metadata(p, \"annotator\")\n",
    "        if annotator == \"anno0\":\n",
    "            continue\n",
    "        annotation_map[p[\"metadata\"][\"review_id\"]][annotator] = p\n",
    "\n",
    "for filename in glob.glob(\"../data_prep/extra_annotations/test/*\"):\n",
    "    with open(filename, 'r') as f:\n",
    "        p = json.load(f)\n",
    "        annotator = get_metadata(p, \"annotator\")\n",
    "        if annotator == \"anno0\":\n",
    "            continue\n",
    "        annotation_map[get_metadata(p, \"review_id\")][get_metadata(p, \"annotator\")] = p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gammas(annotations):\n",
    "    assert len(annotations) == 2\n",
    "    continuum = Continuum()\n",
    "    gammas = {}\n",
    "    all_categories = set([])\n",
    "    for key in \"coarse fine\".split():\n",
    "        key_to_return = \"reb_\" + key\n",
    "        for annotation in annotations:\n",
    "            annotator = get_metadata(annotation, \"annotator\")\n",
    "            new_continuum_items, categories = get_continuum_items_and_categories(\n",
    "                annotation[\"rebuttal_sentences\"], annotator, key)\n",
    "            if not new_continuum_items:\n",
    "                print(\"Error, no segments. Skipping this pair of annotations:\", get_pair_identifier(*annotations))\n",
    "                continuum = None\n",
    "                break\n",
    "            else:\n",
    "                for item in new_continuum_items:\n",
    "                    continuum.add(*item)\n",
    "            all_categories = all_categories.union(categories)\n",
    "        if continuum is not None:\n",
    "            dissim = CombinedCategoricalDissimilarity(alpha=1, beta=2,\n",
    "                        categories=list(sorted(all_categories)))\n",
    "            gamma_results = continuum.compute_gamma(dissim)\n",
    "            gammas[key_to_return] = gamma_results.gamma\n",
    "        else:\n",
    "            gammas[key_to_return] = None\n",
    "    return gammas\n",
    "\n",
    "def get_kappas(two_annotations):\n",
    "    annotation_a, annotation_b = two_annotations\n",
    "    kappa_map = {}\n",
    "\n",
    "    for k, v in annotation_map.items():\n",
    "        if len(v) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            for annotation_a, annotation_b in itertools.combinations(v.values(), 2):\n",
    "                pair_identifier = get_pair_identifier(annotation_a, annotation_b)\n",
    "                label_lists_a = get_label_lists(annotation_a)\n",
    "                label_lists_b = get_label_lists(annotation_b)\n",
    "                kappas = get_kappas_from_label_lists(label_lists_a,\n",
    "                                                    label_lists_b)\n",
    "                for k, v in kappas.items():\n",
    "                    kappa_map[k] = v\n",
    "    return kappa_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ad37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_agreements_map = {}\n",
    "    \n",
    "for k, v in annotation_map.items():\n",
    "    if len(v) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        for two_annotations in itertools.combinations(v.values(), 2): # TODO(TJO): Is this correct for kappa? Or should we only use the two most reliable and leave the rest out of the dataset?\n",
    "            # TODO(TJO): Also, I guess we shouldn't do pairwise for gamma?\n",
    "            agreement_map = get_kappas(two_annotations)\n",
    "            agreement_map.update(get_gammas(two_annotations))\n",
    "            overall_agreements_map[get_pair_identifier(*two_annotations)] = agreement_map\n",
    "    if len(overall_agreements_map) >= 5:\n",
    "        break\n",
    "        \n",
    "print(json.dumps(overall_agreements_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec4b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
